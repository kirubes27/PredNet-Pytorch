{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b156a1d",
   "metadata": {},
   "source": [
    "## Data Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6061edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load data_utils.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import re\n",
    "\n",
    "\n",
    "class SequenceGenerator(data.Dataset):\n",
    "    \"\"\"\n",
    "    Sequence Generator\n",
    "\n",
    "    the role of SequenceGenerator is equal to ImageFolder class in pytorch.\n",
    "\n",
    "    the X_train.h5 contains 41396 images for 57 videos.\n",
    "    the  X_test.h5 contains   832 images for  3 videos.\n",
    "    the   X_val.h5 contains   154 images for  1 videos.\n",
    "\n",
    "    Args:\n",
    "        - data_file:\n",
    "            data path, e.g., '/media/sdb1/chenrui/kitti_data/h5/X_train.h5'\n",
    "        - source_file:\n",
    "            e.g., '/media/sdb1/chenrui/kitti_data/h5/sources_train.h5'\n",
    "            source for each image so when creating sequences can assure that consecutive frames are from same video.\n",
    "                the content is like: 'road-2011_10_03_drive_0047_sync'\n",
    "        - num_timeSteps:\n",
    "            number of timesteps to predict\n",
    "        - seed:\n",
    "            Random seeding for data shuffling.\n",
    "        - shuffle:\n",
    "            shuffle or not\n",
    "        - output_mode:\n",
    "            `error` or `prediction`\n",
    "        - sequence_start_mode:\n",
    "            `all` or `unique`.\n",
    "            `all`: allow for any possible sequence, starting from any frame.\n",
    "            `unique`: create sequences where each unique frame is in at most one sequence\n",
    "        - N_seq:\n",
    "            TODO\n",
    "    \"\"\"\n",
    "    def __init__(self, data_file, source_file, num_timeSteps, shuffle = False, seed = None,\n",
    "                 output_mode = 'error', sequence_start_mode = 'all', N_seq = None, data_format = 'channels_first'):\n",
    "        super(SequenceGenerator, self).__init__()\n",
    "        pattern = re.compile(r'.*?h5/(.+?)\\.h5')\n",
    "        resList = re.findall(pattern, data_file)\n",
    "        print(resList)\n",
    "        varName = resList[0] \n",
    "        h5f = h5py.File(data_file, 'r')\n",
    "        self.X = h5f[varName][:]    # X will be like (n_images, cols, rows, channels) \n",
    "        # self.X = h5f[data_0][:]    # X will be like (n_images, cols, rows, channels) (already printed)\n",
    "\n",
    "        resList = re.findall(pattern, source_file)\n",
    "        varName = resList[0]\n",
    "        source_h5f = h5py.File(source_file, 'r')\n",
    "        #self.sources = source_h5f[data_0][:]   # list\n",
    "        self.sources = source_h5f[varName][:]   # list\n",
    "\n",
    "        self.num_timeSteps = num_timeSteps\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        assert output_mode in {'error', 'prediction'}\n",
    "        self.output_mode = output_mode\n",
    "        assert sequence_start_mode in {'all', 'unique'}\n",
    "        self.sequence_start_mode = sequence_start_mode\n",
    "        self.N_seq = N_seq\n",
    "        self.data_format = data_format\n",
    "        if self.data_format == 'channels_first':\n",
    "            self.X = np.transpose(self.X, (0, 3, 1, 2))\n",
    "        self.img_shape = self.X[0].shape\n",
    "        self.num_samples = self.X.shape[0]\n",
    "\n",
    "        if self.sequence_start_mode == 'all':       # allow for any possible sequence, starting from any frame (如果视频中任意一帧都可以作为起点,只需要确定加上序列长度后的小片段终点是否还属于同一个视频即可)\n",
    "            self.possible_starts = np.array([i for i in range(self.num_samples - self.num_timeSteps) if self.sources[i] == self.sources[i + self.num_timeSteps - 1]])\n",
    "        elif self.sequence_start_mode == 'unique':  # create sequences where each unique frame is in at most one sequence\n",
    "            curr_location = 0\n",
    "            possible_starts = []\n",
    "            while curr_location < self.num_samples - self.num_timeSteps + 1:\n",
    "                if self.sources[curr_location] == self.sources[curr_location + self.num_timeSteps - 1]:\n",
    "                    possible_starts.append(curr_location)\n",
    "                    curr_location += self.num_timeSteps\n",
    "                else:\n",
    "                    curr_location += 1\n",
    "            self.possible_starts = possible_starts\n",
    "\n",
    "        if shuffle:\n",
    "            self.possible_starts = np.random.permutation(self.possible_starts)\n",
    "\n",
    "        if N_seq is not None and len(self.possible_starts) > N_seq:     # select a subset of sequences if want to\n",
    "            self.possible_starts = self.possible_starts[:N_seq]\n",
    "        self.N_sequences = len(self.possible_starts)                    # Number of all possible training segments\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (stacked images, target) where target is NOT class_index of the target class\n",
    "                BUT the order of frames in sorting task.\n",
    "        '''\n",
    "        idx = self.possible_starts[index]\n",
    "        image_group = self.preprocess(self.X[idx : (idx + self.num_timeSteps)])\n",
    "        \n",
    "        if self.output_mode == 'error':\n",
    "            target = 0.             # model outputs errors, so y should be zeros\n",
    "        elif self.output_mode == 'prediction':\n",
    "            target = image_group    # output actual pixels\n",
    "\n",
    "        return image_group, target\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        return X.astype(np.float32) / 255.\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N_sequences\n",
    "\n",
    "    def create_all(self):\n",
    "        '''It is equivalent to create_all in the original code. Serves the evaluate mode and returns all test data.'''\n",
    "        X_all = np.zeros((self.N_sequences, self.num_timeSteps) + self.img_shape, np.float32)\n",
    "        for i, idx in enumerate(self.possible_starts):\n",
    "            X_all[i] = self.preprocess(self.X[idx : (idx + self.num_timeSteps)])\n",
    "        return X_all\n",
    "\n",
    "\n",
    "class ZcrDataLoader(object):\n",
    "    '''[DataLoader for video frame predictation]'''\n",
    "    def __init__(self, data_file, source_file, output_mode, sequence_start_mode, N_seq, args):\n",
    "        super(ZcrDataLoader, self).__init__()\n",
    "        self.data_file = data_file\n",
    "        self.source_file = source_file\n",
    "        self.output_mode = output_mode\n",
    "        self.sequence_start_mode = sequence_start_mode\n",
    "        self.N_seq = N_seq\n",
    "        self.args = args\n",
    "\n",
    "    def dataLoader(self):\n",
    "        image_dataset = SequenceGenerator(self.data_file, self.source_file, self.args.num_timeSteps, self.args.shuffle, None, self.output_mode, self.sequence_start_mode, self.N_seq, self.args.data_format)\n",
    "        # NOTE: Set drop_last to True, you can delete the last incomplete batch (eg, when the data set size is not divisible by batch_size, the number of samples in the last batch is not enough for one batch_size, which may cause some to be used last time The resulting code reports an error because the old size and the new size do not match (PredNet has this problem, so drop_last is set to True here))\n",
    "        dataloader = data.DataLoader(image_dataset, batch_size = self.args.batch_size, shuffle = False, num_workers = self.args.workers, drop_last = True)\n",
    "        return dataloader\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b9df0d",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62bfaa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load debug.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# dataDir = '../coxlab-prednet-cc76248/kitti_data/'\n",
    "# trainSet_path = os.path.join(dataDir, 'X_train.hkl')\n",
    "# train_sources = os.path.join(dataDir, 'sources_train.hkl')\n",
    "# testSet_path = os.path.join(dataDir, 'X_test.hkl')\n",
    "# test_sources = os.path.join(dataDir, 'sources_test.hkl')\n",
    "\n",
    "# @200.121\n",
    "dataDir = 'C:\\\\Users\\\\kirub\\\\Desktop\\\\Summer project 2021\\\\PredNet_pytorch-master\\\\kitti_data\\\\prednet_kitti_data'                 \n",
    "trainSet_path = os.path.join(dataDir, 'X_train.h5')\n",
    "train_sources = os.path.join(dataDir, 'sources_train.h5')\n",
    "testSet_path  = os.path.join(dataDir, 'X_test.h5')\n",
    "test_sources  = os.path.join(dataDir, 'sources_test.h5')\n",
    "\n",
    "valset_path = os.path.join(dataDir, 'X_val.h5')\n",
    "val_sources = os.path.join(dataDir, 'sources_val.h5')\n",
    "\n",
    "\n",
    "\n",
    "h5f = h5py.File(testSet_path,'r')\n",
    "\n",
    "\n",
    "#h5f = h5py.File(testSet_path,'r+')\n",
    "#h5f['data_0']=h5file['X_test'];\n",
    "\n",
    "#abc = h5py.File(trainSet_path,'r')#Extra clarifications for the errors obtained in train.py \n",
    "#dfe = h5py.File(train_sources,'r')#To check names for X_train, sources_train, X_val, sources_val \n",
    "#ghi = h5py.File(valset_path,'r')\n",
    "#jkl = h5py.File(val_sources,'r')\n",
    "\n",
    "#print(list(h5f.keys()))\n",
    "#dset=h5f['data_0']\n",
    "#print(dset.shape)\n",
    "#print(dset.dtype) (already printed)\n",
    "\n",
    "#print(list(abc.keys()))\n",
    "#print(abc['data_0'].shape)\n",
    "#print(list(dfe.keys()))\n",
    "#print(dfe['data_0'].shape)\n",
    "#print(list(ghi.keys()))\n",
    "#print(ghi['data_0'].shape)\n",
    "#print(list(jkl.keys()))\n",
    "#print(jkl['data_0'].shape)\n",
    "\n",
    "testSet = h5f['data_0'][:]\n",
    "\n",
    "# print(testSet)\n",
    "# print(type(testSet))    # <class 'numpy.ndarray'>\n",
    "# print(testSet.shape)    # (832, 128, 160, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6e87e",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbc2341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--mode MODE] [--dataPath PATH]\n",
      "                             [--resultsPath PATH]\n",
      "                             [--checkpoint_file CHECKPOINT_FILE]\n",
      "                             [--batch_size N] [--num_plot N]\n",
      "                             [--num_timeSteps N] [--workers N]\n",
      "                             [--shuffle SHUFFLE] [--data_format DATA_FORMAT]\n",
      "                             [--n_channels N] [--img_height N] [--img_width N]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\kirub\\AppData\\Roaming\\jupyter\\runtime\\kernel-6fb2f742-3858-417b-8683-b6694075ca9b.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kirub\\anaconda3\\envs\\pytorch\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# %load evaluate.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# zcr lib\n",
    "from prednet import PredNet\n",
    "from data_utils import ZcrDataLoader\n",
    "\n",
    "def arg_parse():\n",
    "    desc = \"Video Frames Predicting Task via PredNet.\"\n",
    "    parser = argparse.ArgumentParser(description = desc)\n",
    "\n",
    "    parser.add_argument('--mode', default = 'train', type = str,\n",
    "                        help = 'train or evaluate (default: train)')\n",
    "    parser.add_argument('--dataPath', default = '', type = str, metavar = 'PATH',\n",
    "                        help = 'path to video dataset (default: none)')\n",
    "    parser.add_argument('--resultsPath', default = '', type = str, metavar = 'PATH',\n",
    "                        help = 'saving path to results of PredNet (default: none)')\n",
    "    parser.add_argument('--checkpoint_file', default = '', type = str,\n",
    "                        help = 'checkpoint file for evaluating. (default: none)')\n",
    "    parser.add_argument('--batch_size', default = 32, type = int, metavar = 'N',\n",
    "                        help = 'The size of batch')\n",
    "    parser.add_argument('--num_plot', default = 40, type = int, metavar = 'N',\n",
    "                        help = 'how many images to plot')\n",
    "    parser.add_argument('--num_timeSteps', default = 10, type = int, metavar = 'N',\n",
    "                        help = 'number of timesteps used for sequences in training (default: 10)')\n",
    "    parser.add_argument('--workers', default = 4, type = int, metavar = 'N',\n",
    "                        help = 'number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--shuffle', default = True, type = bool,\n",
    "                        help = 'shuffle or not')\n",
    "    parser.add_argument('--data_format', default = 'channels_last', type = str,\n",
    "                        help = '(c, h, w) or (h, w, c)?')\n",
    "    parser.add_argument('--n_channels', default = 3, type = int, metavar = 'N',\n",
    "                        help = 'The number of input channels (default: 3)')\n",
    "    parser.add_argument('--img_height', default = 128, type = int, metavar = 'N',\n",
    "                        help = 'The height of input frame (default: 128)')\n",
    "    parser.add_argument('--img_width', default = 160, type = int, metavar = 'N',\n",
    "                        help = 'The width of input frame (default: 160)')\n",
    "    # parser.add_argument('--stack_sizes', default = '', type = str,\n",
    "    #                     help = 'Number of channels in targets (A) and predictions (Ahat) in each layer of the architecture.')\n",
    "    # parser.add_argument('--R_stack_sizes', default = '', type = str,\n",
    "    #                     help = 'Number of channels in the representation (R) modules.')\n",
    "    # parser.add_argument('--A_filter_sizes', default = '', type = str,\n",
    "    #                     help = 'Filter sizes for the target (A) modules. (except the target (A) in lowest layer (i.e., input image))')\n",
    "    # parser.add_argument('--Ahat_filter_sizes', default = '', type = str,\n",
    "    #                     help = 'Filter sizes for the prediction (Ahat) modules.')\n",
    "    # parser.add_argument('--R_filter_sizes', default = '', type = str,\n",
    "    #                     help = 'Filter sizes for the representation (R) modules.')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def print_args(args):\n",
    "    print('-' * 50)\n",
    "    for arg, content in args.__dict__.items():\n",
    "        print(\"{}: {}\".format(arg, content))\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "def evaluate(model, args):\n",
    "    '''Evaluate PredNet on KITTI sequences'''\n",
    "    prednet = model     # Now prednet is the testing model (to output predictions)\n",
    "\n",
    "    DATA_DIR = args.dataPath\n",
    "    RESULTS_SAVE_DIR = args.resultsPath\n",
    "    test_file = os.path.join(DATA_DIR, 'X_test.h5')\n",
    "    test_sources = os.path.join(DATA_DIR, 'sources_test.h5')\n",
    "\n",
    "    output_mode = 'prediction'\n",
    "    sequence_start_mode = 'unique'\n",
    "    N_seq = None\n",
    "    dataLoader = ZcrDataLoader(test_file, test_sources, output_mode, sequence_start_mode, N_seq, args).dataLoader()\n",
    "    X_test = dataLoader.dataset.create_all()\n",
    "    # print('X_test.shape', X_test.shape)       # (83, 10, 3, 128, 160)\n",
    "    X_test = X_test[:8, ...]                    # to overcome `cuda runtime error: out of memory`\n",
    "    batch_size = X_test.shape[0]\n",
    "    X_groundTruth = np.transpose(X_test, (1, 0, 2, 3, 4))      # (timesteps, batch_size, 3, 128, 160)\n",
    "    X_groundTruth_list = []\n",
    "    for t in range(X_groundTruth.shape[0]):\n",
    "        X_groundTruth_list.append(np.squeeze(X_groundTruth[t, ...]))    # (batch_size, 3, 128, 160)\n",
    "\n",
    "    X_test = Variable(torch.from_numpy(X_test).float().cuda())\n",
    "\n",
    "    if prednet.data_format == 'channels_first':\n",
    "        input_shape = (batch_size, args.num_timeSteps, n_channels, img_height, img_width)\n",
    "    else:\n",
    "        input_shape = (batch_size, args.num_timeSteps, img_height, img_width, n_channels)\n",
    "    initial_states = prednet.get_initial_states(input_shape)\n",
    "    predictions = prednet(X_test, initial_states)\n",
    "    # print(predictions)\n",
    "    # print(predictions[0].size())    # torch.Size([8, 3, 128, 160])\n",
    "\n",
    "    X_predict_list = [pred.data.cpu().numpy() for pred in predictions]  # length of X_predict_list is timesteps. 每个元素shape是(batch_size, 3, H, W)\n",
    "\n",
    "    # Compare MSE of PredNet predictions vs. using last frame. Write results to prediction_scores.txt\n",
    "    # MSE_PredNet  = np.mean((real_X[:, 1:  ] - pred_X[:, 1:])**2)    # look at all timesteps except the first\n",
    "    # MSE_previous = np.mean((real_X[:,  :-1] - real_X[:, 1:])**2)\n",
    "    # if not os.path.exists(RESULTS_SAVE_DIR):\n",
    "    #     os.mkdir(RESULTS_SAVE_DIR)\n",
    "    # score_file = os.path.join(RESULTS_SAVE_DIR, 'prediction_scores.txt')\n",
    "    # with open(score_file, 'w') as f:\n",
    "    #     f.write(\"PredNet MSE: %f\\n\" % MSE_PredNet)\n",
    "    #     f.write(\"Previous Frame MSE: %f\" % MSE_previous)\n",
    "\n",
    "    # Plot some predictions\n",
    "    if prednet.data_format == 'channels_first':\n",
    "        X_groundTruth_list = [np.transpose(batch_img, (0, 2, 3, 1)) for batch_img in X_groundTruth_list]\n",
    "        X_predict_list     = [np.transpose(batch_img, (0, 2, 3, 1)) for batch_img in X_predict_list]\n",
    "    assert len(X_groundTruth_list) == len(X_predict_list) == args.num_timeSteps\n",
    "    timesteps = args.num_timeSteps\n",
    "    total_num = X_groundTruth_list[0].shape[0]\n",
    "    height = X_predict_list[0].shape[1]\n",
    "    width  = X_predict_list[0].shape[2]\n",
    "\n",
    "    n_plot = args.num_plot\n",
    "    if n_plot > total_num:\n",
    "        n_plot = total_num\n",
    "    aspect_ratio = float(height) / width\n",
    "    plt.figure(figsize = (timesteps, (2 * aspect_ratio)))\n",
    "    gs = gridspec.GridSpec(2, timesteps)\n",
    "    gs.update(wspace = 0., hspace = 0.)\n",
    "    plot_save_dir = os.path.join(RESULTS_SAVE_DIR, 'prediction_plots/')\n",
    "    if not os.path.exists(plot_save_dir):\n",
    "        os.mkdir(plot_save_dir)\n",
    "    plot_idx = np.random.permutation(total_num)[:n_plot]\n",
    "    for i in plot_idx:\n",
    "        for t in range(timesteps):\n",
    "            ## plot the ground truth.\n",
    "            plt.subplot(gs[t])\n",
    "            plt.imshow(X_groundTruth_list[t][i, ...], interpolation = 'none')\n",
    "            plt.tick_params(axis = 'both', which = 'both', bottom = 'off', top = 'off', left = 'off', right = 'off', labelbottom = 'off', labelleft = 'off')\n",
    "            if t == 0:\n",
    "                plt.ylabel('Actual', fontsize = 10)\n",
    "\n",
    "            ## plot the predictions.\n",
    "            plt.subplot(gs[t + timesteps])\n",
    "            plt.imshow(X_predict_list[t][i, ...], interpolation = 'none')\n",
    "            plt.tick_params(axis = 'both', which = 'both', bottom = 'off', top = 'off', left = 'off', right = 'off', labelbottom = 'off', labelleft = 'off')\n",
    "            if t == 0:\n",
    "                plt.ylabel('Predicted', fontsize = 10)\n",
    "\n",
    "        plt.savefig(plot_save_dir +  'plot_' + str(i) + '.png')\n",
    "        plt.clf()\n",
    "    print('The plots are saved in \"%s\"! Have a nice day!' % plot_save_dir)\n",
    "\n",
    "\n",
    "def checkpoint_loader(checkpoint_file):\n",
    "    '''load the checkpoint for weights of PredNet.'''\n",
    "    print('Loading...', end = '')\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    print('Done.')\n",
    "    return checkpoint\n",
    "\n",
    "def load_pretrained_weights(model, state_dict_file):\n",
    "    '''Directly use the parameters taken from the pre-trained PredNet model of the Keras version provided by the original author'''\n",
    "    model = model.load_state_dict(torch.load(state_dict_file))\n",
    "    print('weights loaded!')\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = arg_parse()\n",
    "    print_args(args)\n",
    "\n",
    "    n_channels = args.n_channels\n",
    "    img_height = args.img_height\n",
    "    img_width  = args.img_width\n",
    "\n",
    "    # stack_sizes       = eval(args.stack_sizes)\n",
    "    # R_stack_sizes     = eval(args.R_stack_sizes)\n",
    "    # A_filter_sizes    = eval(args.A_filter_sizes)\n",
    "    # Ahat_filter_sizes = eval(args.Ahat_filter_sizes)\n",
    "    # R_filter_sizes    = eval(args.R_filter_sizes)\n",
    "\n",
    "    stack_sizes       = (n_channels, 48, 96, 192)\n",
    "    R_stack_sizes     = stack_sizes\n",
    "    A_filter_sizes    = (3, 3, 3)\n",
    "    Ahat_filter_sizes = (3, 3, 3, 3)\n",
    "    R_filter_sizes    = (3, 3, 3, 3)\n",
    "\n",
    "    prednet = PredNet(stack_sizes, R_stack_sizes, A_filter_sizes, Ahat_filter_sizes, R_filter_sizes,\n",
    "                      output_mode = 'prediction', data_format = args.data_format, return_sequences = True)\n",
    "    print(prednet)\n",
    "    prednet.cuda()\n",
    "\n",
    "    # print('\\n'.join(['%s:%s' % item for item in prednet.__dict__.items()]))\n",
    "    # print(type(prednet.state_dict()))   # <class 'collections.OrderedDict'>\n",
    "    # for k, v in prednet.state_dict().items():\n",
    "    #     print(k, v.size())\n",
    "\n",
    "    ## Use self-trained parameters\n",
    "    checkpoint_file = args.checkpoint_file\n",
    "    try:\n",
    "        checkpoint = checkpoint_loader(checkpoint_file)\n",
    "    except Exception:\n",
    "        raise(RuntimeError('Cannot load the checkpoint file named %s!' % checkpoint_file))\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    prednet.load_state_dict(state_dict)\n",
    "\n",
    "    ## 直接使用作者提供的预训练参数\n",
    "    # state_dict_file = './model_data_keras2/preTrained_weights_forPyTorch.pkl'\n",
    "    # # prednet = load_pretrained_weights(prednet, state_dict_file)   # 这种不work... why?\n",
    "    # prednet.load_state_dict(torch.load(state_dict_file))\n",
    "\n",
    "    assert args.mode == 'evaluate'\n",
    "    evaluate(prednet, args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0034a8cf",
   "metadata": {},
   "source": [
    "## Evaluate model (Shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load evaluate.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# usage:\n",
    "# \t./evaluate.sh\n",
    "\n",
    "echo \"Evaluate...\"\n",
    "mode='evaluate'\n",
    "\n",
    "# @200.121\n",
    "DATA_DIR='/media/sdb1/chenrui/kitti_data/h5/'\n",
    "# Where results (prediction plots and evaluation file) will be saved.\n",
    "RESULTS_SAVE_DIR='./kitti_results/'\n",
    "checkpoint_file='./checkpoint/checkpoint_epoch1_trLoss1342.3278.pkl'\t# load weights from checkpoint file for evaluating.\n",
    "\n",
    "batch_size=10\n",
    "num_plot=40\t\t# how many images to plot.\n",
    "\n",
    "# number of timesteps used for sequences in evaluating\n",
    "num_timeSteps=10\n",
    "\n",
    "workers=4\n",
    "shuffle=false\n",
    "\n",
    "data_format='channels_first'\n",
    "n_channels=3\n",
    "img_height=128\n",
    "img_width=160\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=2 python evaluate.py \\\n",
    "\t--mode ${mode} \\\n",
    "\t--dataPath ${DATA_DIR} \\\n",
    "\t--resultsPath ${RESULTS_SAVE_DIR} \\\n",
    "\t--checkpoint_file ${checkpoint_file} \\\n",
    "\t--batch_size ${batch_size} \\\n",
    "\t--num_plot ${num_plot} \\\n",
    "\t--num_timeSteps ${num_timeSteps} \\\n",
    "\t--workers ${workers} \\\n",
    "\t--shuffle ${shuffle} \\\n",
    "\t--data_format ${data_format} \\\n",
    "\t--n_channels ${n_channels} \\\n",
    "\t--img_height ${img_height} \\\n",
    "\t--img_width ${img_width}\n",
    "\t# --stack_sizes ${stack_sizes} \\\n",
    "\t# --R_stack_sizes ${R_stack_sizes} \\\n",
    "\t# --A_filter_sizes ${A_filter_sizes} \\\n",
    "\t# --Ahat_filter_sizes ${Ahat_filter_sizes} \\\n",
    "\t# --R_filter_sizes ${R_filter_sizes} \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa09c7fc",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36521e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load load_weights.py\n",
    "\n",
    "'''Load the parameters of the original Keras version of the PredNet model saved in hdf5 into the pytorch version of the model reproduced by zcr.'''\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "# from torch.autograd import Variable\n",
    "\n",
    "\n",
    "weights_file = 'C:\\\\Users\\\\kirub\\\\Desktop\\\\Summer project 2021\\\\PredNet_pytorch-master\\\\model_data_keras2\\\\prednet_kitti_weights.hdf5'\n",
    "weights_f = h5py.File(weights_file, 'r')\n",
    "\n",
    "#print(list(weights_f.items()))\n",
    "#G1=weights_f.get('prednet_1')\n",
    "#print(list(G1.items()))\n",
    "#G2=G1.get('/prednet_1/prednet_1')\n",
    "#print(list(G2.items()))\n",
    "#G3=G1.get('/prednet_1/prednet_1/layer_a_0')\n",
    "#print(list(G3.items()))\n",
    "\n",
    "\n",
    "pred_weights = weights_f['prednet_1']['prednet_1']\t# contains 23 item: 4x4(i,f,c,o for 4 layers) + 4(Ahat for 4 layers) + 3(A for 4 layers)\n",
    "#pred_weights = weights_f['model_weights']['pred_net_1']['pred_net_1']\n",
    "\n",
    "keras_items = ['bias', 'kernel']\n",
    "#keras_items = ['bias:0', 'kernel:0']\n",
    "pytorch_items = ['weight', 'bias']\n",
    "\n",
    "\n",
    "keras_modules = ['a', 'ahat', 'c', 'f', 'i', 'o']\n",
    "keras_modules = ['layer_' + m + '_' + str(i) for m in keras_modules for i in range(4)]\n",
    "keras_modules.remove('layer_a_3')\n",
    "assert len(keras_modules) == 4 * 4 + 4 + 3\n",
    "\n",
    "pytorch_modules_1 = ['A', 'Ahat']\n",
    "pytorch_modules_2 = ['c', 'f', 'i', 'o']\n",
    "pytorch_modules_1 = [m + '.' + str(2 * i) + '.' + item for m in pytorch_modules_1 for i in range(4) for item in pytorch_items]\n",
    "pytorch_modules_1.remove('A.6.weight')\n",
    "pytorch_modules_1.remove('A.6.bias')\n",
    "pytorch_modules_2 = [m + '.' + str(i) + '.' + item for m in pytorch_modules_2 for i in range(4) for item in pytorch_items]\n",
    "pytorch_modules = pytorch_modules_1 + pytorch_modules_2\n",
    "assert len(pytorch_modules) == (4 * 4 + 4 + 3) * 2\n",
    "\n",
    "weight_dict = dict()\n",
    "\n",
    "\n",
    "# Loaded from the h5 file is the weight of type <class'numpy.ndarray'>, which needs to be converted to cuda.Tensor\n",
    "for i in range(len(keras_modules)):\n",
    "\tweight_dict[pytorch_modules[i * 2 + 1]] = pred_weights[keras_modules[i]]['bias'][:]\n",
    "\t# weight_dict[pytorch_modules[i * 2 + 1]] = pred_weights[keras_modules[i]]['bias:0']\n",
    "\tweight_dict[pytorch_modules[i * 2]] = np.transpose(pred_weights[keras_modules[i]]['kernel'][:], (3, 2, 1, 0))\n",
    "\t# weight_dict[pytorch_modules[i * 2]] = pred_weights[keras_modules[i]]['kernel:0']\n",
    "\n",
    "for k, v in weight_dict.items():\n",
    "\t# print(k, v)\n",
    "\t# weight_dict[k] = Variable(torch.from_numpy(v).float().cuda())\n",
    "\tweight_dict[k] = torch.from_numpy(v).float().cuda()\n",
    "\n",
    "fileName = 'C:\\\\Users\\\\kirub\\\\Desktop\\\\Summer project 2021\\\\PredNet_pytorch-master\\\\model_data_keras2\\\\preTrained_weights_forPyTorch.pkl'\n",
    "weights_gift_from_keras = torch.save(weight_dict, fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde1d11",
   "metadata": {},
   "source": [
    "## Prednet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993076b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load prednet.py\n",
    "\n",
    "'''\n",
    "PredNet in PyTorch.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def hard_sigmoid(x):\n",
    "    '''\n",
    "    - hard sigmoid function by zcr.\n",
    "    - Computes element-wise hard sigmoid of x.\n",
    "    - what is hard sigmoid?\n",
    "        Segment-wise linear approximation of sigmoid. Faster than sigmoid.\n",
    "        Returns 0. if x < -2.5, 1. if x > 2.5. In -2.5 <= x <= 2.5, returns 0.2 * x + 0.5.\n",
    "    - See e.g. https://github.com/Theano/Theano/blob/master/theano/tensor/nnet/sigm.py#L279\n",
    "    '''\n",
    "    slope = 0.2\n",
    "    shift = 0.5\n",
    "    x = (slope * x) + shift\n",
    "    x = F.threshold(-x, -1, -1)\n",
    "    x = F.threshold(-x, 0, 0)\n",
    "    return x\n",
    "\n",
    "def get_activationFunc(act_str):\n",
    "    act = act_str.lower()\n",
    "    if act == 'relu':\n",
    "        # return nn.ReLU(True)\n",
    "        return nn.ReLU()\n",
    "    elif act == 'tanh':\n",
    "        # return F.tanh\n",
    "        return nn.Tanh()\n",
    "    # elif act == 'hard_sigmoid':\n",
    "    #     return hard_sigmoid\n",
    "    else:\n",
    "        raise(RuntimeError('cannot obtain the activation function named %s' % act_str))\n",
    "\n",
    "def batch_flatten(x):\n",
    "    '''\n",
    "    equal to the `batch_flatten` in keras.\n",
    "    x is a Variable in pytorch\n",
    "    '''\n",
    "    shape = [*x.size()]\n",
    "    dim = np.prod(shape[1:])\n",
    "    dim = int(dim)      # Without this step, dim is of type <class'numpy.int64'> and cannot be used in the view. Add this step to convert to type <class'int'>.\n",
    "    return x.view(-1, dim)\n",
    "\n",
    "\n",
    "\n",
    "class PredNet(nn.Module):\n",
    "    \"\"\"\n",
    "    PredNet realized by zcr.\n",
    "    \n",
    "    Args:\n",
    "        stack_sizes:\n",
    "            - Number of channels in targets (A) and predictions (Ahat) in each layer of the architecture.\n",
    "            - Length of stack_size (i.e. len(stack_size) and we use `num_layers` to denote it) is the number of layers in the architecture.\n",
    "            - First element is the number of channels in the input.\n",
    "            - e.g., (3, 16, 32) would correspond to a 3 layer architecture that takes in RGB images and\n",
    "              has 16 and 32 channels in the second and third layers, respectively.\n",
    "            - The value of the subscript (lay + 1) is the out_channels parameter of the lay-th convolutional layer in pytorch. For example, the above 16 corresponds to the out_channels of A and Ahat of the lay 0 layer (that is, the input layer) is 16.\n",
    "        R_stack_sizes:\n",
    "            - Number of channels in the representation (R) modules.\n",
    "            - Length must equal length of stack_sizes, but the number of channels per layer can be different.\n",
    "            - That is, the out_channels parameter of the convolutional layer in pytorch.\n",
    "        A_filter_sizes:\n",
    "            - Filter sizes for the target (A) modules. (except the target (A) in lowest layer (i.e., input image))\n",
    "            - Has length of len(stack_sizes) - 1.\n",
    "            - e.g., (3, 3) would mean that targets for layers 2 and 3 are computed by a 3x3 convolution of\n",
    "              the errors (E) from the layer below (followed by max-pooling)\n",
    "            - That is, the kernel_size of the convolutional layer in pytorch.\n",
    "        Ahat_filter_sizes:\n",
    "            - Filter sizes for the prediction (Ahat) modules.\n",
    "            - Has length equal to length of stack_sizes.\n",
    "            - e.g., (3, 3, 3) would mean that the predictions for each layer are computed by a 3x3 convolution\n",
    "              of the representation (R) modules at each layer.\n",
    "            - That is, the kernel_size of the convolutional layer in pytorch.\n",
    "        R_filter_sizes:\n",
    "            - Filter sizes for the representation (R) modules.\n",
    "            - Has length equal to length of stack_sizes.\n",
    "            - Corresponds to the filter sizes for all convolutions in the LSTM.\n",
    "            - That is, the kernel_size of the convolutional layer in pytorch.\n",
    "\n",
    "        pixel_max:\n",
    "            - The maximum pixel value.\n",
    "            - Used to clip the pixel-layer prediction.\n",
    "        error_activation:\n",
    "            - Activation function for the error (E) units.\n",
    "        A_activation:\n",
    "            - Activation function for the target (A) and prediction (A_hat) units.\n",
    "        LSTM_activation:\n",
    "            - Activation function for the cell and hidden states of the LSTM.\n",
    "        LSTM_inner_activation:\n",
    "            - Activation function for the gates in the LSTM.\n",
    "        output_mode:\n",
    "            - Either 'error', 'prediction', 'all' or layer specification (e.g., R2, see below).\n",
    "            - Controls what is outputted by the PredNet.\n",
    "                - if 'error':\n",
    "                    The mean response of the error (E) units of each layer will be outputted.\n",
    "                    That is, the output shape will be (batch_size, num_layers).\n",
    "                - if 'prediction':\n",
    "                    The frame prediction will be outputted.\n",
    "                - if 'all':\n",
    "                    The output will be the frame prediction concatenated with the mean layer errors.\n",
    "                    The frame prediction is flattened before concatenation.\n",
    "                    Note that nomenclature of 'all' means all TYPE of the output (i.e., `error` and `prediction`), but should not be confused with returning all of the layers of the model.\n",
    "                - For returning the features of a particular layer, output_mode should be of the form unit_type + layer_number.\n",
    "                    e.g., to return the features of the LSTM \"representational\" units in the lowest layer, output_mode should be specificied as 'R0'.\n",
    "                    The possible unit types are 'R', 'Ahat', 'A', and 'E' corresponding to the 'representation', 'prediction', 'target', and 'error' units respectively.\n",
    "        extrap_start_time:\n",
    "            - Time step for which model will start extrapolating.\n",
    "            - Starting at this time step, the prediction from the previous time step will be treated as the \"actual\"\n",
    "        data_format:\n",
    "            - 'channels_first': (channel, Height, Width)\n",
    "            - 'channels_last' : (Height, Width, channel)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, stack_sizes, R_stack_sizes, A_filter_sizes, Ahat_filter_sizes, R_filter_sizes,\n",
    "                 pixel_max = 1.0, error_activation = 'relu', A_activation = 'relu', LSTM_activation = 'tanh',\n",
    "                 LSTM_inner_activation = 'hard_sigmoid', output_mode = 'error',\n",
    "                 extrap_start_time = None, data_format = 'channels_last', return_sequences = False):\n",
    "        super(PredNet, self).__init__()\n",
    "        self.stack_sizes = stack_sizes\n",
    "        self.num_layers  = len(stack_sizes)\n",
    "        assert len(R_stack_sizes) == self.num_layers\n",
    "        self.R_stack_sizes = R_stack_sizes\n",
    "        assert len(A_filter_sizes) == self.num_layers - 1\n",
    "        self.A_filter_sizes = A_filter_sizes\n",
    "        assert len(Ahat_filter_sizes) == self.num_layers\n",
    "        self.Ahat_filter_sizes = Ahat_filter_sizes\n",
    "        assert len(R_filter_sizes) == self.num_layers\n",
    "        self.R_filter_sizes = R_filter_sizes\n",
    "\n",
    "        self.pixel_max = pixel_max\n",
    "        self.error_activation = error_activation\n",
    "        self.A_activation = A_activation\n",
    "        self.LSTM_activation = LSTM_activation\n",
    "        self.LSTM_inner_activation = LSTM_inner_activation\n",
    "\n",
    "        default_output_modes = ['prediction', 'error', 'all']\n",
    "        layer_output_modes = [layer + str(n) for n in range(self.num_layers) for layer in ['R', 'E', 'A', 'Ahat']]\n",
    "        assert output_mode in default_output_modes + layer_output_modes\n",
    "        self.output_mode = output_mode\n",
    "        if self.output_mode in layer_output_modes:\n",
    "            self.output_layer_type = self.output_mode[:-1]\n",
    "            self.output_layer_NO = int(self.output_mode[-1])    # suppose the number of layers is < 10\n",
    "        else:\n",
    "            self.output_layer_type = None\n",
    "            self.output_layer_NO = None\n",
    "\n",
    "        self.extrap_start_time = extrap_start_time\n",
    "        assert data_format in ['channels_first', 'channels_last']\n",
    "        self.data_format = data_format\n",
    "        if self.data_format == 'channels_first':\n",
    "            self.channel_axis = -3\n",
    "            self.row_axis = -2\n",
    "            self.col_axis = -1\n",
    "        else:\n",
    "            self.channel_axis = -1\n",
    "            self.row_axis = -3\n",
    "            self.col_axis = -2\n",
    "\n",
    "        self.return_sequences = return_sequences\n",
    "\n",
    "        self.make_layers()\n",
    "\n",
    "\n",
    "    def get_initial_states(self, input_shape):\n",
    "        '''\n",
    "        input_shape is like: (batch_size, timeSteps, Height, Width, 3)\n",
    "                         or: (batch_size, timeSteps, 3, Height, Width)\n",
    "        '''\n",
    "        init_height = input_shape[self.row_axis]     # equal to `init_nb_rows` in original version\n",
    "        init_width  = input_shape[self.col_axis]     # equal to `init_nb_cols` in original version\n",
    "\n",
    "        base_initial_state = np.zeros(input_shape)\n",
    "        non_channel_axis = -1 if self.data_format == 'channels_first' else -2\n",
    "        for _ in range(2):\n",
    "            base_initial_state = np.sum(base_initial_state, axis = non_channel_axis)\n",
    "        base_initial_state = np.sum(base_initial_state, axis = 1)   # (batch_size, 3)\n",
    "\n",
    "        initial_states = []\n",
    "        states_to_pass = ['R', 'c', 'E']    # R is `representation`, c is Cell state in LSTM, E is `error`.\n",
    "        layerNum_to_pass = {sta: self.num_layers for sta in states_to_pass}\n",
    "        if self.extrap_start_time is not None:\n",
    "            states_to_pass.append('Ahat')   # pass prediction in states so can use as actual for t+1 when extrapolating\n",
    "            layerNum_to_pass['Ahat'] = 1\n",
    "\n",
    "        for sta in states_to_pass:\n",
    "            for lay in range(layerNum_to_pass[sta]):\n",
    "                downSample_factor = 2 ** lay            # Downsampling scaling factor\n",
    "                row = init_height // downSample_factor\n",
    "                col = init_width  // downSample_factor\n",
    "                if sta in ['R', 'c']:\n",
    "                    stack_size = self.R_stack_sizes[lay]\n",
    "                elif sta == 'E':\n",
    "                    stack_size = self.stack_sizes[lay] * 2\n",
    "                elif sta == 'Ahat':\n",
    "                    stack_size = self.stack_sizes[lay]\n",
    "                output_size = stack_size * row * col    # flattened size\n",
    "                reducer = np.zeros((input_shape[self.channel_axis], output_size))   # (3, output_size)\n",
    "                initial_state = np.dot(base_initial_state, reducer)                 # (batch_size, output_size)\n",
    "\n",
    "                if self.data_format == 'channels_first':\n",
    "                    output_shape = (-1, stack_size, row, col)\n",
    "                else:\n",
    "                    output_shape = (-1, row, col, stack_size)\n",
    "                # initial_state = torch.from_numpy(np.reshape(initial_state, output_shape)).float().cuda()\n",
    "                initial_state = Variable(torch.from_numpy(np.reshape(initial_state, output_shape)).float().cuda(), requires_grad = True)\n",
    "                initial_states += [initial_state]\n",
    "\n",
    "        if self.extrap_start_time is not None:\n",
    "            # initial_states += [torch.IntTensor(1).zero_().cuda()]   # the last state will correspond to the current timestep\n",
    "            initial_states += [Variable(torch.IntTensor(1).zero_().cuda())]   # the last state will correspond to the current timestep\n",
    "        return initial_states\n",
    "\n",
    "\n",
    "    # def compute_output_shape(self, input_shape):\n",
    "    #     if self.output_mode == 'prediction':\n",
    "    #         out_shape = input_shape[2:]\n",
    "    #     elif self.output_mode == 'error':   # The error mode output is the error of each layer, with a scalar for each layer\n",
    "    #         out_shape = (self.num_layers,)\n",
    "    #     elif self.output_mode == 'all':\n",
    "    #         out_shape = (np.prod(input_shape[2:]) + self.num_layers,)   # np.prod multiply the elements one by one\n",
    "    #     else:\n",
    "    #         if self.output_layer_type == 'R':\n",
    "    #             stack_str = 'R_stack_sizes'\n",
    "    #         else:\n",
    "    #             stack_str = 'stack_sizes'\n",
    "\n",
    "    #         if self.output_layer_type == 'E':\n",
    "    #             stack_multi = 2\n",
    "    #         else:\n",
    "    #             stack_multi = 1\n",
    "\n",
    "    #         out_stack_size = stack_multi * getattr(self, stack_str)[self.output_layer_NO]\n",
    "    #         layer_out_row = input_shape[self.row_axis] / (2 ** self.output_layer_NO)\n",
    "    #         layer_out_col = input_shape[self.col_axis] / (2 ** self.output_layer_NO)\n",
    "    #         if self.data_format == 'channels_first':\n",
    "    #             out_shape = (out_stack_size, layer_out_row, layer_out_col)\n",
    "    #         else:\n",
    "    #             out_shape = (layer_out_row, layer_out_col, out_stack_size)\n",
    "\n",
    "    #         if self.return_sequences:\n",
    "    #             return (input_shape[0], input_shape[1]) + out_shape    # input_shape[1] is the timesteps\n",
    "    #         else:\n",
    "    #             return (input_shape[0],) + out_shape\n",
    "\n",
    "\n",
    "    def isNotTopestLayer(self, layerIndex):\n",
    "        '''judge if the layerIndex is not the topest layer.'''\n",
    "        if layerIndex < self.num_layers - 1:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def make_layers(self):\n",
    "        '''\n",
    "        equal to the `build` method in original version.\n",
    "        '''\n",
    "        # i: input, f: forget, c: cell, o: output\n",
    "        self.conv_layers = {item: [] for item in ['i', 'f', 'c', 'o', 'A', 'Ahat']}\n",
    "        lstm_list = ['i', 'f', 'c', 'o']\n",
    "\n",
    "        for item in sorted(self.conv_layers.keys()):\n",
    "            for lay in range(self.num_layers):\n",
    "                downSample_factor = 2 ** lay        # Downsampling scaling factor\n",
    "                if item == 'Ahat':\n",
    "                    in_channels = self.R_stack_sizes[lay]   # Because Ahat convolves the output of R, the number of channels input to Ahat is the number of output channels of R in the same layer.\n",
    "                    self.conv_layers['Ahat'].append(nn.Conv2d(in_channels = in_channels,\n",
    "                                                              out_channels = self.stack_sizes[lay],\n",
    "                                                              kernel_size = self.Ahat_filter_sizes[lay],\n",
    "                                                              stride = (1, 1),\n",
    "                                                              padding = int((self.Ahat_filter_sizes[lay] - 1) / 2)    # the `SAME` mode (i.e.,(kernel_size - 1) / 2)\n",
    "                                                              ))\n",
    "                    act = 'relu' if lay == 0 else self.A_activation\n",
    "                    self.conv_layers['Ahat'].append(get_activationFunc(act))\n",
    "\n",
    "                elif item == 'A':\n",
    "                    if self.isNotTopestLayer(lay):   # Here is just to control the number of layers (one less than other such as Ahat)\n",
    "                        # NOTE: Here is the construction of A from the second layer (lay = 1) (because the A of the lowest layer (layer0) of the entire network is the original image (the A of layer0 can be regarded as an identity layer, that is, the input image, Output the image as it is))\n",
    "                        in_channels = self.R_stack_sizes[lay] * 2   # The number of input features of the A convolutional layer (in_channels) is the number of features of the corresponding layer E. E contains two parts (Ahat-A) and (A-Ahat), so x2. [From the left picture of Fig.1 of the paper, E The output of Ahat is subtracted from A, and then spliced.)\n",
    "                        self.conv_layers['A'].append(nn.Conv2d(in_channels = in_channels,\n",
    "                                                               out_channels = self.stack_sizes[lay + 1],\n",
    "                                                               kernel_size = self.A_filter_sizes[lay],\n",
    "                                                               stride = (1, 1),\n",
    "                                                               padding = int((self.A_filter_sizes[lay] - 1) / 2)    # the `SAME` mode\n",
    "                                                               ))\n",
    "                        self.conv_layers['A'].append(get_activationFunc(self.A_activation))\n",
    "\n",
    "                elif item in lstm_list:     # Build the R module\n",
    "                    # The number of input features of R (in_channels): the sum of the number of features of E in the same layer, R at the same time at the same time (i.e. R_t-1), and R at the same time engraved on the upper layer (i.e. R_l+1).\n",
    "                    # If the R module is on the top layer, there is no R from the upper layer. Among them:\n",
    "                    # -stack_sizes[lay] * 2 represents the number of channels in the same layer E (because E is obtained by splicing A and Ahat in the same layer in the channel dimension, so x2)\n",
    "                    # -R_stack_sizes[lay] represents the number of R channels on the same layer at a time\n",
    "                    # -R_stack_sizes[lay + 1] represents the number of channels that engrave the upper layer of R at the same time\n",
    "                    in_channels = self.stack_sizes[lay] * 2 + self.R_stack_sizes[lay]\n",
    "                    if self.isNotTopestLayer(lay):\n",
    "                        in_channels += self.R_stack_sizes[lay + 1]\n",
    "                    # for j in lstm_list:     # Serious bug! Quickly comment out... the following forward indentation 4 spaces...\n",
    "                    # The non-linear activation function layer of i, f, c, and o in LSTM is implemented in forward. (Because i, f, o use hard_sigmoid function here, LSTM in Keras is hard_sigmoid by default, but you need to implement it yourself in pytorch)\n",
    "                    # act = self.LSTM_activation if j == 'c' else self.LSTM_inner_activation\n",
    "                    # act = get_activationFunc(act)\n",
    "                    self.conv_layers[item].append(nn.Conv2d(in_channels = in_channels,\n",
    "                                                         out_channels = self.R_stack_sizes[lay],\n",
    "                                                         kernel_size = self.R_filter_sizes[lay],\n",
    "                                                         stride = (1, 1),\n",
    "                                                         padding = int((self.R_filter_sizes[lay] - 1) / 2)    # the `SAME` mode\n",
    "                                                         ))\n",
    "\n",
    "        for name, layerList in self.conv_layers.items():\n",
    "            self.conv_layers[name] = nn.ModuleList(layerList)\n",
    "            setattr(self, name, self.conv_layers[name])\n",
    "\n",
    "        # see the source code in:\n",
    "        #     [PyTorch]: http://pytorch.org/docs/master/_modules/torch/nn/modules/upsampling.html\n",
    "        #     [Keras  ]: keras-master/keras/layers/convolution.py/`class UpSampling2D(Layer)`\n",
    "        # self.upSample = nn.Upsample(size = (2, 2), mode = 'nearest')  # It's wrong! The scale_factor parameter in pytorch corresponds to the size parameter in keras.\n",
    "        self.upSample = nn.Upsample(scale_factor = 2, mode = 'nearest')\n",
    "        # see the source code in:\n",
    "        #     [PyTorch]: http://pytorch.org/docs/master/_modules/torch/nn/modules/pooling.html#MaxPool2d\n",
    "        #     [Keras  ]: keras-master/keras/layers/pooling.py/``\n",
    "        # `pool_size` in Keras is equal to `kernel_size` in pytorch.\n",
    "        # [TODO] padding here is not very clear. Is `0` here is the `SAME` mode in Keras?\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "\n",
    "\n",
    "    def step(self, A, states):\n",
    "        '''\n",
    "        This step function is equivalent to the `step` function in the original code. It is the core logic of PredNet.\n",
    "        Analogous to the implementation of standard LSTM, the role of this step function is equivalent to LSTMCell, and the following forward function is equivalent to the LSTM class.\n",
    "\n",
    "        Args:\n",
    "            A: 4D tensor with the shape of (batch_size, 3, Height, Width). It is the data extracted from A_withTimeStep according to the time step.\n",
    "            The form of the `initial_states` of the states and `forward` functions is exactly the same, except that the latter is the initialized PredNet state, and the states here are the PredNet parameters when calculating in timesteps.\n",
    "        '''\n",
    "        n = self.num_layers\n",
    "        R_current = states[       :    (n)]\n",
    "        c_current = states[    (n):(2 * n)]\n",
    "        E_current = states[(2 * n):(3 * n)]\n",
    "\n",
    "        if self.extrap_start_time is not None:\n",
    "            timestep = states[-1]\n",
    "            if timestep >= self.t_extrap:   # if past self.extrap_start_time, the previous prediction will be treated as the actual.\n",
    "                A = states[-2]\n",
    "            else:\n",
    "                A = A\n",
    "\n",
    "        R_list = []\n",
    "        c_list = []\n",
    "        E_list = []\n",
    "\n",
    "        # Update R units starting from the top.\n",
    "        for lay in reversed(range(self.num_layers)):\n",
    "            inputs = [R_current[lay], E_current[lay]]   # If it is the top level, there are only two inputs for R_l: E_l^t, R_l^(t-1). That is, there are no input items for the high-level R module.\n",
    "            if self.isNotTopestLayer(lay):              # If it is not the top level, R_l has three inputs: E_l^t, R_l^(t-1), R_(l+1)^t. R_up is R_(l+1)^t\n",
    "                inputs.append(R_up)\n",
    "            \n",
    "            inputs = torch.cat(inputs, dim = self.channel_axis)\n",
    "            if not isinstance(inputs, Variable):        # In the first time step, the inputs are still of Tensor type, but after going through the network, they will be of Variable type in subsequent time steps.\n",
    "                inputs = Variable(inputs, requires_grad = True)\n",
    "\n",
    "            # print(lay, type(inputs), inputs.size())   # In the right case, an example is as follows:\n",
    "            # lay3: torch.Size([8, 576, 16, 20])  [576 = 384(E_l^t) + 192(R_l^(t-1))]\n",
    "            # lay2: torch.Size([8, 480, 32, 40])  [480 = 192(E_l^t) +  96(R_l^(t-1)) + 192(R_(l+1)^t)]\n",
    "            # lay1: torch.Size([8, 240, 64, 80])  [240 =  96(E_l^t) +  48(R_l^(t-1)) +  96(R_(l+1)^t)]\n",
    "            # lay0: torch.Size([8, 57, 160, 128]) [ 57 =   6(E_l^t) +   3(R_l^(t-1)) +  48(R_(l+1)^t)]\n",
    "\n",
    "            # see https://github.com/huggingface/torchMoji/blob/master/torchmoji/lstm.py\n",
    "            in_gate     = hard_sigmoid(self.conv_layers['i'][lay](inputs))\n",
    "            forget_gate = hard_sigmoid(self.conv_layers['f'][lay](inputs))\n",
    "            cell_gate   = F.tanh(self.conv_layers['c'][lay](inputs))\n",
    "            out_gate    = hard_sigmoid(self.conv_layers['o'][lay](inputs))\n",
    "\n",
    "            # print(forget_gate.size())       # torch.Size([8, 192, 16, 20])\n",
    "            # print(c_current[lay].size())    # torch.Size([8, 192, 16, 20])\n",
    "            # print(in_gate.size())           # torch.Size([8, 192, 16, 20])\n",
    "            # print(cell_gate.size())         # torch.Size([8, 192, 16, 20])\n",
    "            # print(type(forget_gate))        # <class 'torch.autograd.variable.Variable'>\n",
    "            # print(type(c_current[lay]))     # <class 'torch.cuda.FloatTensor'>\n",
    "            # print(type(Variable(c_current[lay])))     # <class 'torch.autograd.variable.Variable'>\n",
    "            # print(type(in_gate))            # <class 'torch.autograd.variable.Variable'>\n",
    "            # print(type(cell_gate))          # <class 'torch.autograd.variable.Variable'>\n",
    "            if not isinstance(c_current[lay], Variable):\n",
    "                c_current[lay] = Variable(c_current[lay], requires_grad = True)\n",
    "            c_next = (forget_gate * c_current[lay]) + (in_gate * cell_gate)     # Multiply corresponding elements\n",
    "            R_next = out_gate * F.tanh(c_next)      # `R_next` here is equivalent to the hidden state in the standard LSTM.This is the representation of the video.\n",
    "\n",
    "            c_list.insert(0, c_next)\n",
    "            R_list.insert(0, R_next)\n",
    "\n",
    "            if lay > 0:\n",
    "                # R_up = self.upSample(R_next).data     # Note: What comes out here is Variable, the ones that need to be appended to the input list above are all FloatTensor, so it needs to be changed into Tensor form here, that is, add a `.data`\n",
    "                R_up = self.upSample(R_next)            # NOTE:This is the reason why the loss.backward() error is reported for a long time: the error caused by mixing Tensor and Variable in torch.cat()!\n",
    "                # print(R_up.size())  # lay3: torch.Size([8, 192, 32, 40])\n",
    "\n",
    "\n",
    "        # Update feedforward path starting from the bottom.\n",
    "        for lay in range(self.num_layers):\n",
    "            Ahat = self.conv_layers['Ahat'][2 * lay](R_list[lay])   # Ahat is the convolution of R, so input the R in the same layer at the same time. Please pay attention here: each `lay` actually corresponds to two components: convolutional layer + nonlinear activation layer, so you need to use (2 * lay) to index the convolutional layer corresponding to `lay`, and (2 * lay + 1) to index the nonlinear activation function layer corresponding to `lay`. The same is true for A below.\n",
    "            Ahat = self.conv_layers['Ahat'][2 * lay + 1](Ahat)      # Don't forget the nonlinear activation. The following is the same for A.\n",
    "            if lay == 0:\n",
    "                # Ahat = torch.min(Ahat, self.pixel_max)            # Error (representation in keras)\n",
    "                Ahat[Ahat > self.pixel_max] = self.pixel_max        # passed through a saturating non-linearity set at the maximum pixel value\n",
    "                frame_prediction = Ahat                             # The Ahat of the lowest layer is the predicted output frame image\n",
    "                # if self.output_mode == 'prediction':\n",
    "                #     break\n",
    "            \n",
    "            # print('&' * 10, lay)\n",
    "            # print('Ahat', Ahat.size())  # torch.Size([batch_size, 3, 128, 160])\n",
    "            # print('A', A.size())        # It turns out that A0 directly uses the data loaded from the dataloader, so torch.Size([batch_size, 10, 3, 128, 160]) is printed, and this is the problem: the data returned by the dataloader is (batch_size, timesteps, (image_shape)), but actually used in RNN is to separate each time step. Now decouple the core logic to form a `step` function, A0 becomes torch.Size([batch_size, 3, 128, 160]) this dimension.\n",
    "            # print('&' * 20)\n",
    "            \n",
    "            # compute errors\n",
    "            if self.error_activation.lower() == 'relu':\n",
    "                E_up   = F.relu(Ahat - A)\n",
    "                E_down = F.relu(A - Ahat)\n",
    "            elif self.error_activation.lower() == 'tanh':\n",
    "                E_up   = F.tanh(Ahat - A)\n",
    "                E_down = F.tanh(A - Ahat)\n",
    "            else:\n",
    "                raise(RuntimeError('cannot obtain the activation function named %s' % self.error_activation))\n",
    "            \n",
    "            E_list.append(torch.cat((E_up, E_down), dim = self.channel_axis))\n",
    "\n",
    "            # If you want to get the output of a specific module in a specific layer:\n",
    "            if self.output_layer_NO == lay:\n",
    "                if   self.output_layer_type == 'A':\n",
    "                    output = A\n",
    "                elif self.output_layer_type == 'Ahat':\n",
    "                    output = Ahat\n",
    "                elif self.output_layer_type == 'R':\n",
    "                    output = R_list[lay]\n",
    "                elif self.output_layer_type == 'E':\n",
    "                    output = E_list[lay]\n",
    "\n",
    "            if self.isNotTopestLayer(lay):\n",
    "                A = self.conv_layers['A'][2 * lay](E_list[lay])     # After convolution + pooling on E, you get A that is engraved with a layer at the same time. If the layer is already the topmost layer, you don't need it\n",
    "                A = self.conv_layers['A'][2 * lay + 1](A)           # Don't forget the nonlinear activation.\n",
    "                A = self.pool(A)    # target for next layer\n",
    "        \n",
    "\n",
    "        if self.output_layer_type is None:\n",
    "            if self.output_mode == 'prediction':\n",
    "                output = frame_prediction\n",
    "            else:\n",
    "                for lay in range(self.num_layers):\n",
    "                    layer_error = torch.mean(batch_flatten(E_list[lay]), dim = -1, keepdim = True)     # The batch_flatten function is implemented by zcr in accordance with the function of the same name in Kears. The 0th dimension is the batch_size dimension, and the dimensions other than this dimension are flattened\n",
    "                    all_error = layer_error if lay == 0 else torch.cat((all_error, layer_error), dim = -1)\n",
    "                if self.output_mode == 'error':\n",
    "                    output = all_error\n",
    "                else:\n",
    "                    output = torch.cat((batch_flatten(frame_prediction), all_error), dim = -1)\n",
    "\n",
    "        states = R_list + c_list + E_list\n",
    "        if self.extrap_start_time is not None:\n",
    "            states += [frame_prediction, (timestep + 1)]\n",
    "        return output, states\n",
    "\n",
    "\n",
    "    def forward(self, A0_withTimeStep, initial_states):\n",
    "        '''\n",
    "        A0_withTimeStep is the input from dataloader. Its shape is: (batch_size, timesteps, 3, Height, Width).\n",
    "            To put it bluntly, this A0_withTimeStep is the original image loaded by the dataloader, that is, the A of the lowest layer (layer 0), but it is expanded in the two dimensions of batch_size and timestep.\n",
    "        initial_states  is a list of pytorch-tensors. The states parameter is actually the initial state, because the forword function itself is not executed in a loop.\n",
    "\n",
    "        NOTE: The purpose of this forward function is to implement the step function of the original Keras version, but it is not the same as the latter. Because the PredNet class of the original code is\n",
    "              Inherited the `Recurrent` class in Keras, so it seems that the parent class implements the loading of dataloader (ie SequenceGenerator in the original code)\n",
    "              The data (batch_size, timesteps, 3, H, W) is decomposed into (batch_size, 3, H, W), and then the solution is looped for timesteps.\n",
    "              And the forward here needs to implement the loop timesteps by yourself. The shape of A here is the 5D tensor (batch_size, timesteps, 3, Height, Width) from the dataloader,\n",
    "              The shape of the input `x` of the step function in the original code is 4D tensor (batch_size, 3, Height, Width).\n",
    "        '''\n",
    "\n",
    "        # The default is batch_fist == True, that is, the first dimension is batch_size, and the second dimension is timesteps.\n",
    "        A0_withTimeStep = A0_withTimeStep.transpose(0, 1)   # (b, t, c, h, w) -> (t, b, c, h, w)\n",
    "\n",
    "        num_timesteps = A0_withTimeStep.size()[0]\n",
    "\n",
    "        hidden_states = initial_states    # Assigned to hidden_states is to be used painlessly in the following loop\n",
    "        output_list = []                  # The output needs to be retained: In the error mode, it needs to be weighted according to the layer and timestep to get the final loss; in the prediction mode, it is necessary to output the predicted image at each time step (for example, if the timestep is 10, output 10 images)\n",
    "        for t in range(num_timesteps):\n",
    "            '''\n",
    "                The original LSTM (or ordinary RNN) requires two cycles:\n",
    "                for lay in range(num_layers):\n",
    "                    for t in range(num_timesteps):\n",
    "                        pass\n",
    "                \n",
    "But as the footnote part of the original Keras version of the code said: Although PredNet sets the number of layers, it is actually implemented using\n",
    "A super layer (`super layer`) is implemented, that is, it is a layer itself. So there is no for lay loop here.\n",
    "            '''\n",
    "            A0 = A0_withTimeStep[t, ...]\n",
    "            output, hidden_states = self.step(A0, hidden_states)\n",
    "            output_list.append(output)\n",
    "            # hidden_states There is no need to keep it, just let it carry out the iteration of the'Yangtze River Back Wave Push Forward Wave' type within the time step.\n",
    "\n",
    "        if self.output_mode == 'error':\n",
    "            '''Perform weighting according to layer and timestep. Different from the way of adding Dense layer in the original code, the weighting operation can be directly written in the PredNet model (in this if statement), or the error of each layer in all time steps can be returned, Calculate in the main function. zcr chooses the latter (consistent with the original code)'''\n",
    "            # print(len(output_list))             # 10, The number of timesteps\n",
    "            # print('output: ', output_list)      # The `error` of each time step is a matrix of (batch_size, num_layer), and the type is Variable. [torch.cuda.FloatTensor of size 8x4 (GPU 0)] According to this, weighting according to layer and timestep can be achieved. Calculation! (Two types of weighting according to the layer, you can get the so-called two types of loss of `L_0` and `L_all`)\n",
    "            # print('Got the `error` list with the length of len(timeSteps) and shape of each element in this list is: (batch_size, num_layer).')\n",
    "            return output_list\n",
    "        elif self.output_mode == 'prediction':\n",
    "            return output_list  # The output_list at this time is the timestep prediction frame image\n",
    "        elif self.output_mode == 'all':\n",
    "            pass\n",
    "        else:\n",
    "            raise(RuntimeError('Kidding? Unknown output mode!'))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n_channels = 3\n",
    "    img_height = 128\n",
    "    img_width  = 160\n",
    "\n",
    "    stack_sizes       = (n_channels, 48, 96, 192)\n",
    "    R_stack_sizes     = stack_sizes\n",
    "    A_filter_sizes    = (3, 3, 3)\n",
    "    Ahat_filter_sizes = (3, 3, 3, 3)\n",
    "    R_filter_sizes    = (3, 3, 3, 3)\n",
    "\n",
    "    prednet = PredNet(stack_sizes, R_stack_sizes, A_filter_sizes, Ahat_filter_sizes, R_filter_sizes,\n",
    "                      output_mode = 'error', return_sequences = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63f296",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81231532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "mode: train\n",
      "dataPath: \n",
      "checkpoint_savePath: \n",
      "epochs: 20\n",
      "batch_size: 32\n",
      "optimizer: SGD\n",
      "lr: 0.01\n",
      "momentum: 0.9\n",
      "beta1: 0.9\n",
      "beta2: 0.99\n",
      "workers: 4\n",
      "checkpoint_file: \n",
      "printCircle: 100\n",
      "data_format: channels_last\n",
      "n_channels: 3\n",
      "img_height: 128\n",
      "img_width: 160\n",
      "layer_loss_weightsMode: L_0\n",
      "num_timeSteps: 10\n",
      "shuffle: True\n",
      "--------------------------------------------------\n",
      "PredNet(\n",
      "  (i): ModuleList(\n",
      "    (0): Conv2d(57, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(480, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (f): ModuleList(\n",
      "    (0): Conv2d(57, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(480, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (c): ModuleList(\n",
      "    (0): Conv2d(57, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(480, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (o): ModuleList(\n",
      "    (0): Conv2d(57, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(240, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(480, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(576, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (A): ModuleList(\n",
      "    (0): Conv2d(6, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (Ahat): ModuleList(\n",
      "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (upSample): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-73d504d62d8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprednet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-73d504d62d8c>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, args)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0msequence_start_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mN_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mdataLoader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZcrDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_sources\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence_start_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprednet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Summer project 2021\\PredNet_pytorch-master\\data_utils.py\u001b[0m in \u001b[0;36mdataLoader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[0mimage_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequenceGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msource_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timeSteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_start_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;31m# NOTE: 将drop_last设置为True, 可以删除最后一个不完整的batch(e.g.,当数据集大小不能被batch_size整除时, 最后一个batch的样本数是不够一个batch_size的, 这可能会导致某些要用到上一次结果的代码因为旧size和新size不匹配而报错(PredNet就有这个问题, 故这里将drop_last设置为True))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Summer project 2021\\PredNet_pytorch-master\\data_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_file, source_file, num_timeSteps, shuffle, seed, output_mode, sequence_start_mode, N_seq, data_format)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'.*?h5/(.+?)\\.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mresList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mvarName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mh5f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvarName\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m    \u001b[1;31m# X will be like (n_images, cols, rows, channels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# %load train.py\n",
    "import traceback\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# zcr lib\n",
    "from prednet import PredNet\n",
    "from data_utils import ZcrDataLoader\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = 1\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def arg_parse():\n",
    "    desc = \"Video Frames Predicting Task via PredNet.\"\n",
    "    parser = argparse.ArgumentParser(description = desc)\n",
    "\n",
    "    parser.add_argument('--mode', default = 'train', type = str,\n",
    "                        help = 'train or evaluate (default: train)')\n",
    "    parser.add_argument('--dataPath', default = '', type = str, metavar = 'PATH',\n",
    "                        help = 'path to video dataset (default: none)')\n",
    "    parser.add_argument('--checkpoint_savePath', default = '', type = str, metavar = 'PATH',\n",
    "                        help = 'path for saving checkpoint file (default: none)')\n",
    "    parser.add_argument('--epochs', default = 20, type = int, metavar='N',\n",
    "                        help = 'number of total epochs to run')\n",
    "    parser.add_argument('--batch_size', default = 32, type = int, metavar = 'N',\n",
    "                        help = 'The size of batch')\n",
    "    parser.add_argument('--optimizer', default = 'SGD', type = str,\n",
    "                        help = 'which optimizer to use')\n",
    "    parser.add_argument('--lr', default = 0.01, type = float,\n",
    "                        metavar = 'LR', help = 'initial learning rate')\n",
    "    parser.add_argument('--momentum', default = 0.9, type = float,\n",
    "                        help = 'momentum for SGD')\n",
    "    parser.add_argument('--beta1', default = 0.9, type = float,\n",
    "                        help = 'beta1 in Adam optimizer')\n",
    "    parser.add_argument('--beta2', default = 0.99, type = float,\n",
    "                        help = 'beta2 in Adam optimizer')\n",
    "    parser.add_argument('--workers', default = 4, type = int, metavar = 'N',\n",
    "                        help = 'number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--checkpoint_file', default = '', type = str,\n",
    "                        help = 'path to checkpoint file for restrating (default: none)')\n",
    "    parser.add_argument('--printCircle', default = 100, type = int, metavar = 'N',\n",
    "                        help = 'how many steps to print the loss information')\n",
    "    parser.add_argument('--data_format', default = 'channels_last', type = str,\n",
    "                        help = '(c, h, w) or (h, w, c)?')\n",
    "    parser.add_argument('--n_channels', default = 3, type = int, metavar = 'N',\n",
    "                        help = 'The number of input channels (default: 3)')\n",
    "    parser.add_argument('--img_height', default = 128, type = int, metavar = 'N',\n",
    "                        help = 'The height of input frame (default: 128)')\n",
    "    parser.add_argument('--img_width', default = 160, type = int, metavar = 'N',\n",
    "                        help = 'The width of input frame (default: 160)')\n",
    "    # parser.add_argument('--stack_sizes', default = '', type = str,\n",
    "    #                     help = 'Number of channels in targets (A) and predictions (Ahat) in each layer of the architecture.')\n",
    "    # parser.add_argument('--R_stack_sizes', default = '', type = str,\n",
    "    #                     help = 'Number of channels in the representation (R) modules.')\n",
    "    # parser.add_argument('--A_filter_sizes', default = '', type = str,\n",
    "    #                     help = 'Filter sizes for the target (A) modules. (except the target (A) in lowest layer (i.e., input image))')\n",
    "    # parser.add_argument('--Ahat_filter_sizes', default = '', type = str,\n",
    "    #                     help = 'Filter sizes for the prediction (Ahat) modules.')\n",
    "    # parser.add_argument('--R_filter_sizes', default = '', type = str,\n",
    "    #                     help = 'Filter sizes for the representation (R) modules.')\n",
    "    parser.add_argument('--layer_loss_weightsMode', default = 'L_0', type = str,\n",
    "                        help = 'L_0 or L_all for loss weights in PredNet')\n",
    "    parser.add_argument('--num_timeSteps', default = 10, type = int, metavar = 'N',\n",
    "                        help = 'number of timesteps used for sequences in training (default: 10)')\n",
    "    parser.add_argument('--shuffle', default = True, type = bool,\n",
    "                        help = 'shuffle or not')\n",
    "    \n",
    "    #args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "def print_args(args):\n",
    "    print('-' * 50)\n",
    "    for arg, content in args.__dict__.items():\n",
    "        print(\"{}: {}\".format(arg, content))\n",
    "    print('-' * 50)\n",
    "\n",
    "def train(model, args):\n",
    "    '''Train PredNet on KITTI sequences'''\n",
    "    \n",
    "    # print('layer_loss_weightsMode: ', args.layer_loss_weightsMode)\n",
    "    prednet = model\n",
    "    # frame data files\n",
    "    DATA_DIR = args.dataPath\n",
    "    train_file = os.path.join(DATA_DIR, 'X_train.h5')\n",
    "    train_sources = os.path.join(DATA_DIR, 'sources_train.h5')\n",
    "    val_file = os.path.join(DATA_DIR, 'X_val.h5')\n",
    "    val_sources = os.path.join(DATA_DIR, 'sources_val.h5')\n",
    "\n",
    "    output_mode = 'error'\n",
    "    sequence_start_mode = 'all'\n",
    "    N_seq = None\n",
    "    dataLoader = ZcrDataLoader(train_file, train_sources, output_mode, sequence_start_mode, N_seq, args).dataLoader()\n",
    "    \n",
    "    if prednet.data_format == 'channels_first':\n",
    "        input_shape = (args.batch_size, args.num_timeSteps, n_channels, img_height, img_width)\n",
    "    else:\n",
    "        input_shape = (args.batch_size, args.num_timeSteps, img_height, img_width, n_channels)\n",
    "\n",
    "    optimizer = torch.optim.Adam(prednet.parameters(), lr = args.lr)\n",
    "    lr_maker  = lr_scheduler.StepLR(optimizer = optimizer, step_size = 75, gamma = 0.1)  # decay the lr every 50 epochs by a factor of 0.1\n",
    "\n",
    "    printCircle = args.printCircle\n",
    "    for e in range(args.epochs):\n",
    "        tr_loss = 0.0\n",
    "        sum_trainLoss_in_epoch = 0.0\n",
    "        min_trainLoss_in_epoch = float('inf')\n",
    "        startTime_epoch = time.time()\n",
    "        lr_maker.step()\n",
    "\n",
    "        initial_states = prednet.get_initial_states(input_shape)    # 原网络貌似不是stateful的, 故这里再每个epoch开始时重新初始化(如果是stateful的, 则只在全部的epoch开始时初始化一次)\n",
    "        states = initial_states\n",
    "        for step, (frameGroup, target) in enumerate(dataLoader):\n",
    "            # print(frameGroup)   # [torch.FloatTensor of size 16x12x80x80]\n",
    "            batch_frames = Variable(frameGroup.cuda())\n",
    "            batch_y = Variable(target.cuda())\n",
    "            output = prednet(batch_frames, states)\n",
    "\n",
    "            # '''进行按照timestep和layer对error进行加权.'''\n",
    "            ## 1. 按layer加权(巧妙利用广播. NOTE: 这里的error列表里的每个元素是Variable类型的矩阵, 需要转成numpy矩阵类型才可以用切片.)\n",
    "            num_layer = len(stack_sizes)\n",
    "            # weighting for each layer in final loss\n",
    "            if args.layer_loss_weightsMode == 'L_0':        # e.g., [1., 0., 0., 0.]\n",
    "                layer_weights = np.array([0. for _ in range(num_layer)])\n",
    "                layer_weights[0] = 1.\n",
    "                layer_weights = torch.from_numpy(layer_weights)\n",
    "                # layer_weights = torch.from_numpy(np.array([1., 0., 0., 0.]))\n",
    "            elif args.layer_loss_weightsMode == 'L_all':    # e.g., [1., 1., 1., 1.]\n",
    "                layer_weights = np.array([0.1 for _ in range(num_layer)])\n",
    "                layer_weights[0] = 1.\n",
    "                layer_weights = torch.from_numpy(layer_weights)\n",
    "                # layer_weights = torch.from_numpy(np.array([1., 0.1, 0.1, 0.1]))\n",
    "            else:\n",
    "                raise(RuntimeError('Unknown loss weighting mode! Please use `L_0` or `L_all`.'))\n",
    "            # layer_weights = Variable(layer_weights.float().cuda(), requires_grad = False)  # NOTE: layer_weights默认是DoubleTensor, 而下面的error是FloatTensor的Variable, 如果直接相乘会报错!\n",
    "            layer_weights = Variable(layer_weights.float().cuda())  # NOTE: layer_weights默认是DoubleTensor, 而下面的error是FloatTensor的Variable, 如果直接相乘会报错!\n",
    "            error_list = [batch_x_numLayer__error * layer_weights for batch_x_numLayer__error in output]    # 利用广播实现加权\n",
    "\n",
    "            ## 2. 按timestep进行加权. (paper: equally weight all timesteps except the first)\n",
    "            num_timeSteps = args.num_timeSteps\n",
    "            time_loss_weight  = (1. / (num_timeSteps - 1))\n",
    "            time_loss_weight  = Variable(torch.from_numpy(np.array([time_loss_weight])).float().cuda())\n",
    "            time_loss_weights = [time_loss_weight for _ in range(num_timeSteps - 1)]\n",
    "            time_loss_weights.insert(0, Variable(torch.from_numpy(np.array([0.])).float().cuda()))\n",
    "\n",
    "            error_list = [error_at_t.sum() for error_at_t in error_list]   # 是一个Variable的列表\n",
    "            total_error = error_list[0] * time_loss_weights[0]\n",
    "            for err, time_weight in zip(error_list[1:], time_loss_weights[1:]):\n",
    "                total_error = total_error + err * time_weight\n",
    "\n",
    "            loss = total_error\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # if (step + 1) == 2500:\n",
    "            #     zcr_state_dict = {\n",
    "            #         'epoch'     : (e + 1),\n",
    "            #         'tr_loss'   : 0,\n",
    "            #         'state_dict': prednet.state_dict(),\n",
    "            #         'optimizer' : optimizer.state_dict()\n",
    "            #     }\n",
    "            #     saveCheckpoint(zcr_state_dict)\n",
    "\n",
    "            # print('epoch: [%3d/%3d] | step: [%4d/%4d]  loss: %.4f' % ((e + 1), args.epochs, (step + 1), len(dataLoader), loss.data[0]))\n",
    "\n",
    "            tr_loss += loss.data[0]\n",
    "            sum_trainLoss_in_epoch += loss.data[0]\n",
    "            if step % printCircle == (printCircle - 1):\n",
    "                print('epoch: [%3d/%3d] | [%4d/%4d]  loss: %.4f  lr: %.5lf' % ((e + 1), args.epochs, (step + 1), len(dataLoader), tr_loss / printCircle, optimizer.param_groups[0]['lr']))\n",
    "                tr_loss = 0.0\n",
    "\n",
    "        endTime_epoch = time.time()\n",
    "        print('Time Consumed within an epoch: %.2f (s)' % (endTime_epoch - startTime_epoch))\n",
    "\n",
    "        if sum_trainLoss_in_epoch < min_trainLoss_in_epoch:\n",
    "            min_trainLoss_in_epoch = sum_trainLoss_in_epoch\n",
    "            zcr_state_dict = {\n",
    "                'epoch'     : (e + 1),\n",
    "                'tr_loss'   : min_trainLoss_in_epoch,\n",
    "                'state_dict': prednet.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict()\n",
    "            }\n",
    "            saveCheckpoint(zcr_state_dict)\n",
    "\n",
    "\n",
    "def saveCheckpoint(zcr_state_dict, fileName = 'C:\\\\Users\\\\kirub\\\\Desktop\\\\Summer project 2021\\\\PredNet_pytorch-master\\\\checkpoint\\\\checkpoint_newest.pkl'):\n",
    "    '''save the checkpoint for both restarting and evaluating.'''\n",
    "    tr_loss  = '%.4f' % zcr_state_dict['tr_loss']\n",
    "    # val_loss = '%.4f' % zcr_state_dict['val_loss']\n",
    "    epoch = zcr_state_dict['epoch']\n",
    "    # fileName = './checkpoint/checkpoint_epoch' + str(epoch) + '_trLoss' + tr_loss + '_valLoss' + val_loss + '.pkl'\n",
    "    fileName = 'C:\\\\Users\\\\kirub\\\\Desktop\\\\Summer project 2021\\\\PredNet_pytorch-master\\\\checkpoint\\\\PredNet\\\\checkpoint_epoch' + str(epoch) + '_trLoss' + tr_loss + '.pkl'\n",
    "    torch.save(zcr_state_dict, fileName)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = arg_parse()\n",
    "    print_args(args)\n",
    "\n",
    "    # DATA_DIR = args.dataPath\n",
    "    # data_file = os.path.join(DATA_DIR, 'X_test.h5')\n",
    "    # source_file = os.path.join(DATA_DIR, 'sources_test.h5')\n",
    "    # output_mode = 'error'\n",
    "    # sequence_start_mode = 'all'\n",
    "    # N_seq = None\n",
    "    # dataLoader = ZcrDataLoader(data_file, source_file, output_mode, sequence_start_mode, N_seq, args).dataLoader()\n",
    "\n",
    "    # images, target = next(iter(dataLoader))\n",
    "    # print(images)\n",
    "    # print(target)\n",
    "\n",
    "    n_channels = args.n_channels\n",
    "    img_height = args.img_height\n",
    "    img_width  = args.img_width\n",
    "\n",
    "    # stack_sizes       = eval(args.stack_sizes)\n",
    "    # R_stack_sizes     = eval(args.R_stack_sizes)\n",
    "    # A_filter_sizes    = eval(args.A_filter_sizes)\n",
    "    # Ahat_filter_sizes = eval(args.Ahat_filter_sizes)\n",
    "    # R_filter_sizes    = eval(args.R_filter_sizes)\n",
    "\n",
    "    stack_sizes       = (n_channels, 48, 96, 192)\n",
    "    R_stack_sizes     = stack_sizes\n",
    "    A_filter_sizes    = (3, 3, 3)\n",
    "    Ahat_filter_sizes = (3, 3, 3, 3)\n",
    "    R_filter_sizes    = (3, 3, 3, 3)\n",
    "\n",
    "    prednet = PredNet(stack_sizes, R_stack_sizes, A_filter_sizes, Ahat_filter_sizes, R_filter_sizes,\n",
    "                      output_mode = 'error', data_format = args.data_format, return_sequences = True)\n",
    "    print(prednet)\n",
    "    prednet.cuda()\n",
    "\n",
    "    assert args.mode == 'train'\n",
    "    train(prednet, args)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb959e4c",
   "metadata": {},
   "source": [
    "## Train Model (Shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8701a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load train.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# usage:\n",
    "# \t./train.sh\n",
    "\n",
    "echo \"Train...\"\n",
    "mode='train'\n",
    "\n",
    "# @200.121\n",
    "DATA_DIR='/media/sdb1/chenrui/kitti_data/h5/'\n",
    "checkpoint_savePath='./checkpoint/'\n",
    "checkpoint_file='./checkpoint/'\t# checkpoint file name for restarting.\n",
    "\n",
    "epochs=1\n",
    "batch_size=8\n",
    "optimizer='Adam'\n",
    "learning_rate=0.001\n",
    "momentum=0.9\n",
    "beta1=0.9\n",
    "beta2=0.99\n",
    "\n",
    "workers=4\n",
    "\n",
    "# it is vital for restarting\n",
    "checkpoint_file='./checkpoint/'\n",
    "printCircle=100\n",
    "\n",
    "data_format='channels_first'\n",
    "n_channels=3\n",
    "img_height=128\n",
    "img_width=160\n",
    "\n",
    "# stack_sizes=\"($n_channels, 48, 96, 192)\"\n",
    "# R_stack_sizes=$stack_sizes\n",
    "# A_filter_sizes=\"(3, 3, 3)\"\n",
    "# Ahat_filter_sizes=\"(3, 3, 3, 3)\"\n",
    "# R_filter_sizes=\"(3, 3, 3, 3)\"\n",
    "\n",
    "layer_loss_weightsMode='L_0'\n",
    "# layer_loss='L_all'\n",
    "\n",
    "# number of timesteps used for sequences in training\n",
    "num_timeSteps=10\n",
    "\n",
    "shuffle=true\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 python train.py \\\n",
    "\t--mode ${mode} \\\n",
    "\t--dataPath ${DATA_DIR} \\\n",
    "\t--checkpoint_savePath ${checkpoint_savePath} \\\n",
    "\t--epochs ${epochs} \\\n",
    "\t--batch_size ${batch_size} \\\n",
    "\t--optimizer ${optimizer} \\\n",
    "\t--lr ${learning_rate} \\\n",
    "\t--momentum ${momentum} \\\n",
    "\t--beta1 ${beta1} \\\n",
    "\t--beta2 ${beta2} \\\n",
    "\t--workers ${workers} \\\n",
    "\t--checkpoint_file ${checkpoint_file} \\\n",
    "\t--printCircle ${printCircle} \\\n",
    "\t--data_format ${data_format} \\\n",
    "\t--n_channels ${n_channels} \\\n",
    "\t--img_height ${img_height} \\\n",
    "\t--img_width ${img_width} \\\n",
    "\t--layer_loss_weightsMode ${layer_loss_weightsMode} \\\n",
    "\t--num_timeSteps ${num_timeSteps} \\\n",
    "\t--shuffle ${shuffle}\n",
    "\t# --stack_sizes ${stack_sizes} \\\n",
    "\t# --R_stack_sizes ${R_stack_sizes} \\\n",
    "\t# --A_filter_sizes ${A_filter_sizes} \\\n",
    "\t# --Ahat_filter_sizes ${Ahat_filter_sizes} \\\n",
    "\t# --R_filter_sizes ${R_filter_sizes} \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88994b99",
   "metadata": {},
   "source": [
    "## Viusalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load visualization.py\n",
    "\n",
    "\n",
    "'''\n",
    "Usage:\n",
    "    python visualization.py\n",
    "'''\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def sortByVariance(filtersData):\n",
    "    '''resort the filters by variance.'''\n",
    "    sumedData = np.sum(filtersData, axis = 3)\n",
    "    flat = sumedData.reshape(sumedData.shape[0], sumedData.shape[1] * sumedData.shape[2])\n",
    "    std = np.std(flat, axis = 1)\n",
    "    order = np.argsort(std)\n",
    "    filterNum = int(order.shape[0] - (order.shape[0] % 10))     # e.g., 57——>50\n",
    "    sortedData = np.zeros((filterNum,) + filtersData.shape[1:])\n",
    "    for i in range(filterNum):\n",
    "        sortedData[i, :, :, :] = filtersData[order[i], :, :, :]\n",
    "    return sortedData\n",
    "\n",
    "def visualize(filtersData, output_figName):\n",
    "    '''\n",
    "    visualize the conv1 filters\n",
    "    filtersData: (filters_num, height, width, 3)\n",
    "    '''\n",
    "    print(output_figName)\n",
    "    filtersData = np.squeeze(filtersData)\n",
    "    print('after squeeze: ', filtersData.shape)     # (96, 11, 11, 3)\n",
    "\n",
    "    # normalize filtersData for display\n",
    "    filtersData = (filtersData - filtersData.min()) / (filtersData.max() - filtersData.min())\n",
    "    filtersData = sortByVariance(filtersData)\n",
    "    print('after sorting: ', filtersData.shape)     # (96, 11, 11, 3)\n",
    "\n",
    "    filters_num = filtersData.shape[0]\n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(filters_num)))\n",
    "    # add some space between filters\n",
    "    padding = (((0, 0), (0, 1), (0, 1)) + ((0, 0),) * (filtersData.ndim - 3))   # don't pad the last dimension (if there is one)\n",
    "    # padding = (((0, 64 - filters_num), (0, 1), (0, 1)) + ((0, 0),) * (filtersData.ndim - 3))   # don't pad the last dimension (if there is one)\n",
    "    print(padding)  # ((0, 0), (0, 1), (0, 1), (0, 0))\n",
    "    filtersData = np.pad(filtersData, padding, mode = 'constant', constant_values = 1)  # pad with ones (white)\n",
    "    print('after padding: ', filtersData.shape)     # (96, 12, 12, 3)\n",
    "    # tile the filters into an image\n",
    "    filtersData = filtersData.reshape((5, 10) + filtersData.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, filtersData.ndim + 1)))\n",
    "    print('after reshape1: ', filtersData.shape)    # (6, 12, 16, 12, 3)\n",
    "    # filtersData = filtersData.reshape((8, 8) + filtersData.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, filtersData.ndim + 1)))\n",
    "    filtersData = filtersData.reshape((5 * filtersData.shape[1], 10 * filtersData.shape[3]) + filtersData.shape[4:])\n",
    "    print('after reshape2: ', filtersData.shape)    # (72, 192, 3)\n",
    "    # filtersData = filtersData.reshape((8 * filtersData.shape[1], 8 * filtersData.shape[3]) + filtersData.shape[4:])\n",
    "    \n",
    "    plt.imshow(filtersData)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_figName, bbox_inches = 'tight')\n",
    "\n",
    "def get_filtersData(checkpoint_file):\n",
    "    '''get the filters data from checkpoint file.'''\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    stateDict = checkpoint['state_dict']\n",
    "    ## debug\n",
    "    # for k, v in stateDict.items():\n",
    "    #     print(k)\n",
    "    conv1_filters = stateDict['feature.0.weight']\n",
    "    conv1_filters = conv1_filters.cpu().numpy() # if no `.cpu()`: RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). Use .cpu() to move the tensor to host memory first.\n",
    "    conv1_filters = conv1_filters.transpose(0, 2, 3, 1)\n",
    "    # print(conv1_filters.shape)  # (96, 11, 11, 12)\n",
    "    return conv1_filters\n",
    "\n",
    "def visualize_layer2(filtersData, output_figName):\n",
    "    '''A.2.weight'''\n",
    "    filtersData = np.squeeze(filtersData)\n",
    "    print('after squeeze: ', filtersData.shape)\n",
    "\n",
    "    # normalize filtersData for display\n",
    "    filtersData = (filtersData - filtersData.min()) / (filtersData.max() - filtersData.min())\n",
    "\n",
    "    sumedData = np.sum(filtersData, axis = 3)\n",
    "    flat = sumedData.reshape(sumedData.shape[0], sumedData.shape[1] * sumedData.shape[2])\n",
    "    std = np.std(flat, axis = 1)\n",
    "    order = np.argsort(std)\n",
    "    # filterNum = int(order.shape[0] - (order.shape[0] % 10))\n",
    "    sortedData = np.zeros(filtersData.shape)\n",
    "    for i in range(filtersData.shape[0]):\n",
    "        sortedData[i, :, :, :] = filtersData[order[i], :, :, :]\n",
    "    filtersData = sortedData\n",
    "    print('after sorting: ', filtersData.shape)\n",
    "\n",
    "    filters_num = filtersData.shape[0]\n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(filters_num)))\n",
    "    # add some space between filters\n",
    "    padding = (((0, 0), (0, 1), (0, 1)) + ((0, 0),) * (filtersData.ndim - 3))   # don't pad the last dimension (if there is one)\n",
    "    # padding = (((0, 64 - filters_num), (0, 1), (0, 1)) + ((0, 0),) * (filtersData.ndim - 3))   # don't pad the last dimension (if there is one)\n",
    "    print(padding)  # ((0, 0), (0, 1), (0, 1), (0, 0))\n",
    "    filtersData = np.pad(filtersData, padding, mode = 'constant', constant_values = 1)  # pad with ones (white)\n",
    "    print('after padding: ', filtersData.shape)     # (96, 12, 12, 3)\n",
    "    # tile the filters into an image\n",
    "    filtersData = filtersData.reshape((3, 16) + filtersData.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, filtersData.ndim + 1)))\n",
    "    print('after reshape1: ', filtersData.shape)    # (6, 12, 16, 12, 3)\n",
    "    # filtersData = filtersData.reshape((8, 8) + filtersData.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, filtersData.ndim + 1)))\n",
    "    filtersData = filtersData.reshape((3 * filtersData.shape[1], 16 * filtersData.shape[3]) + filtersData.shape[4:])\n",
    "    print('after reshape2: ', filtersData.shape)    # (72, 192, 3)\n",
    "    # filtersData = filtersData.reshape((8 * filtersData.shape[1], 8 * filtersData.shape[3]) + filtersData.shape[4:])\n",
    "    \n",
    "    plt.imshow(filtersData)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_figName, bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    state_dict_file = 'C:\\\\Users\\\\kirub\\\\Desktop\\\\Summer project 2021\\\\PredNet_pytorch-master\\\\model_data_keras2\\\\preTrained_weights_forPyTorch.pkl'\n",
    "    stateDict = torch.load(state_dict_file)\n",
    "    modules = ['A', 'Ahat', 'c', 'f', 'i', 'o']\n",
    "    # for m in modules:\n",
    "    #     # kernel = stateDict[m + '.0.weight'].cpu().numpy()\n",
    "    #     kernel = stateDict[m + '.0.weight'].cpu()\n",
    "    #     # print(kernel.shape)\n",
    "    #     # A: (48, 6, 3, 3)\n",
    "    #     # Ahat: (3, 3, 3, 3)\n",
    "    #     # c、f、i、o: (3, 57, 3, 3)\n",
    "    #     # kernel = F.upsample(input = Variable(kernel), scale_factor = 2, mode = 'nearest')\n",
    "    #     # kernel = F.upsample(input = Variable(kernel), scale_factor = 4, mode = 'nearest')\n",
    "    #     # kernel = F.upsample(input = Variable(kernel), scale_factor = 2, mode = 'bilinear')\n",
    "    #     # kernel = F.upsample(input = Variable(kernel), scale_factor = 4, mode = 'bilinear')\n",
    "    #     # kernel = F.upsample(input = Variable(kernel), scale_factor = 2, mode = 'linear')  # 不行, linear只接受3D输入\n",
    "    #     print(kernel.data.size())\n",
    "    #     kernel = kernel.data.numpy()\n",
    "    #     kernel = np.transpose(kernel, (1, 2, 3, 0))\n",
    "    #     if m in ['c', 'f', 'i', 'o']:\n",
    "    #         visualize(kernel, './conv1_filters/' + m + '.png')\n",
    "\n",
    "    # kernel = stateDict['A.2.weight'].cpu()  # (96, 96, 3, 3)\n",
    "    kernel = stateDict['Ahat.2.weight'].cpu()  # (48, 48, 3, 3)\n",
    "    kernel = F.upsample(input = Variable(kernel), scale_factor = 4, mode = 'bilinear')\n",
    "    kernel = kernel.data.numpy()\n",
    "    kernel = np.transpose(kernel, (1, 2, 3, 0))[..., :3]    # orz...原来有96个'RGB通道', 无法显示成图像, 人为截取前三维\n",
    "    print('before calling visualization func: ', kernel.shape)\n",
    "    visualize_layer2(kernel, './conv1_filters/Ahat.2.kernel.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a457f6",
   "metadata": {},
   "source": [
    "## Preprocessed KITTI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a29e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "savedir=\"kitti_data\"\n",
    "!mkdir-p--\"$savedir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0680ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-06-30 21:17:38--  https://www.dropbox.com/s/rpwlnn6j39jjme4/kitti_data.zip?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 2620:100:6031:18::a27d:5112, 162.125.81.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|2620:100:6031:18::a27d:5112|:443... connected.\n",
      "WARNING: cannot verify www.dropbox.com's certificate, issued by 'CN=DigiCert SHA2 High Assurance Server CA,OU=www.digicert.com,O=DigiCert Inc,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/rpwlnn6j39jjme4/kitti_data.zip [following]\n",
      "--2021-06-30 21:17:39--  https://www.dropbox.com/s/raw/rpwlnn6j39jjme4/kitti_data.zip\n",
      "Reusing existing connection to [www.dropbox.com]:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com/cd/0/inline/BRbRuRFMIokZwa2-nmkwfM9zVIgTNr12FzrWz_JNbD3IGXTQbGNxtD9ZmS37DGhWnSznFpId5DIRcjKf7olCQNhx-YFetYl80vMUGSy3uibwe5RoWb-JMDzcJdss_oA96S6dfuXrog3EfMOvsDmqM4tU/file# [following]\n",
      "--2021-06-30 21:17:39--  https://uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com/cd/0/inline/BRbRuRFMIokZwa2-nmkwfM9zVIgTNr12FzrWz_JNbD3IGXTQbGNxtD9ZmS37DGhWnSznFpId5DIRcjKf7olCQNhx-YFetYl80vMUGSy3uibwe5RoWb-JMDzcJdss_oA96S6dfuXrog3EfMOvsDmqM4tU/file\n",
      "Resolving uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com (uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com)... 2620:100:6031:15::a27d:510f, 162.125.81.15\n",
      "Connecting to uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com (uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com)|2620:100:6031:15::a27d:510f|:443... connected.\n",
      "WARNING: cannot verify uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com's certificate, issued by 'CN=DigiCert TLS RSA SHA256 2020 CA1,O=DigiCert Inc,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /cd/0/inline2/BRZFXIco79l2jI84n2SJ3aTGx4i5sv6Oi9mevdjE32JeqdgnvmRv70NUP4qBkL7vkatL1pktfgkysLv8nhgL1r1w3zdfSO_DHE6XH6o-9RIWNuo4n0vOwGpaPeY41jzp77hN-ZRUTnGnY_zdDpSa8TaQ3sZxz_MX9VhCiwBvDxmgwA8Vq865Vvb4GWffOVIpski-FR8CBeHVBDzrFC_bobtQu1tfEPuul4ESEPzBFYJ4p5X09p-FmzreWUdO6slbAF32gB28x2zZXPCD8yxH4ti4GTLlY1gyUPlSEOyv75wSz9Y33Zkm5xJ2mNl17SfbqAFA-VP8qbw3kE2WFDeJOQ2POp_RnafkgN3nsiLy6CLqutVi5npT81JVX_OQoKj_vEo/file [following]\n",
      "--2021-06-30 21:17:41--  https://uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com/cd/0/inline2/BRZFXIco79l2jI84n2SJ3aTGx4i5sv6Oi9mevdjE32JeqdgnvmRv70NUP4qBkL7vkatL1pktfgkysLv8nhgL1r1w3zdfSO_DHE6XH6o-9RIWNuo4n0vOwGpaPeY41jzp77hN-ZRUTnGnY_zdDpSa8TaQ3sZxz_MX9VhCiwBvDxmgwA8Vq865Vvb4GWffOVIpski-FR8CBeHVBDzrFC_bobtQu1tfEPuul4ESEPzBFYJ4p5X09p-FmzreWUdO6slbAF32gB28x2zZXPCD8yxH4ti4GTLlY1gyUPlSEOyv75wSz9Y33Zkm5xJ2mNl17SfbqAFA-VP8qbw3kE2WFDeJOQ2POp_RnafkgN3nsiLy6CLqutVi5npT81JVX_OQoKj_vEo/file\n",
      "Reusing existing connection to [uc1a2becd9268443431c961cbed1.dl.dropboxusercontent.com]:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2064447587 (1.9G) [application/zip]\n",
      "Saving to: 'kitti_data/prednet_kitti_data.zip'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  122K 4h34m\n",
      "    50K .......... .......... .......... .......... ..........  0% 81.3K 5h44m\n",
      "   100K .......... .......... .......... .......... ..........  0%  163K 4h58m\n",
      "   150K .......... .......... .......... .......... ..........  0% 14.5M 3h44m\n",
      "   200K .......... .......... .......... .......... ..........  0% 20.0M 2h59m\n",
      "   250K .......... .......... .......... .......... ..........  0%  165K 3h3m\n",
      "   300K .......... .......... .......... .......... ..........  0% 6.66M 2h38m\n",
      "   350K .......... .......... .......... .......... ..........  0%  125K 2h51m\n",
      "   400K .......... .......... .......... .......... ..........  0%  237K 2h48m\n",
      "   450K .......... .......... .......... .......... ..........  0% 11.4M 2h32m\n",
      "   500K .......... .......... .......... .......... ..........  0% 11.4M 2h18m\n",
      "   550K .......... .......... .......... .......... ..........  0% 15.7M 2h7m\n",
      "   600K .......... .......... .......... .......... ..........  0%  265K 2h7m\n",
      "   650K .......... .......... .......... .......... ..........  0% 5.59M 1h58m\n",
      "   700K .......... .......... .......... .......... ..........  0% 1.56M 1h51m\n",
      "   750K .......... .......... .......... .......... ..........  0% 1.57M 1h46m\n",
      "   800K .......... .......... .......... .......... ..........  0%  372K 1h45m\n",
      "   850K .......... .......... .......... .......... ..........  0% 21.2M 99m32s\n",
      "   900K .......... .......... .......... .......... ..........  0%  215K 1h42m\n",
      "   950K .......... .......... .......... .......... ..........  0% 2.24M 98m6s\n",
      "  1000K .......... .......... .......... .......... ..........  0% 15.3M 93m32s\n",
      "  1050K .......... .......... .......... .......... ..........  0% 14.3M 89m23s\n",
      "  1100K .......... .......... .......... .......... ..........  0%  972K 87m0s\n",
      "  1150K .......... .......... .......... .......... ..........  0%  153K 92m30s\n",
      "  1200K .......... .......... .......... .......... ..........  0%  227K 94m43s\n",
      "  1250K .......... .......... .......... .......... ..........  0% 18.5M 91m8s\n",
      "  1300K .......... .......... .......... .......... ..........  0% 16.4M 87m50s\n",
      "  1350K .......... .......... .......... .......... ..........  0% 15.1M 84m46s\n",
      "  1400K .......... .......... .......... .......... ..........  0% 1.02M 82m58s\n",
      "  1450K .......... .......... .......... .......... ..........  0% 19.3M 80m15s\n",
      "  1500K .......... .......... .......... .......... ..........  0% 14.4M 77m44s\n",
      "  1550K .......... .......... .......... .......... ..........  0% 15.3M 75m22s\n",
      "  1600K .......... .......... .......... .......... ..........  0% 14.6M 73m9s\n",
      "  1650K .......... .......... .......... .......... ..........  0% 19.0M 71m3s\n",
      "  1700K .......... .......... .......... .......... ..........  0% 4.37M 69m14s\n",
      "  1750K .......... .......... .......... .......... ..........  0% 5.73M 67m28s\n",
      "  1800K .......... .......... .......... .......... ..........  0% 17.5M 65m41s\n",
      "  1850K .......... .......... .......... .......... ..........  0% 10.5M 64m3s\n",
      "  1900K .......... .......... .......... .......... ..........  0% 12.8M 62m28s\n",
      "  1950K .......... .......... .......... .......... ..........  0% 12.8M 60m58s\n",
      "  2000K .......... .......... .......... .......... ..........  0% 11.7M 59m33s\n",
      "  2050K .......... .......... .......... .......... ..........  0% 15.4M 58m11s\n",
      "  2100K .......... .......... .......... .......... ..........  0% 17.4M 56m52s\n",
      "  2150K .......... .......... .......... .......... ..........  0% 12.9M 55m38s\n",
      "  2200K .......... .......... .......... .......... ..........  0% 18.0M 54m26s\n",
      "  2250K .......... .......... .......... .......... ..........  0% 18.5M 53m17s\n",
      "  2300K .......... .......... .......... .......... ..........  0%  979K 52m53s\n",
      "  2350K .......... .......... .......... .......... ..........  0% 3.97M 51m57s\n",
      "  2400K .......... .......... .......... .......... ..........  0% 5.01M 51m1s\n",
      "  2450K .......... .......... .......... .......... ..........  0% 4.78M 50m8s\n",
      "  2500K .......... .......... .......... .......... ..........  0% 4.83M 49m17s\n",
      "  2550K .......... .......... .......... .......... ..........  0% 4.84M 48m28s\n",
      "  2600K .......... .......... .......... .......... ..........  0% 5.57M 47m40s\n",
      "  2650K .......... .......... .......... .......... ..........  0% 5.59M 46m53s\n",
      "  2700K .......... .......... .......... .......... ..........  0% 5.89M 46m8s\n",
      "  2750K .......... .......... .......... .......... ..........  0% 4.82M 45m26s\n",
      "  2800K .......... .......... .......... .......... ..........  0% 7.19M 44m43s\n",
      "  2850K .......... .......... .......... .......... ..........  0% 5.72M 44m2s\n",
      "  2900K .......... .......... .......... .......... ..........  0% 6.84M 43m22s\n",
      "  2950K .......... .......... .......... .......... ..........  0% 4.82M 42m46s\n",
      "  3000K .......... .......... .......... .......... ..........  0% 7.14M 42m8s\n",
      "  3050K .......... .......... .......... .......... ..........  0% 6.08M 41m33s\n",
      "  3100K .......... .......... .......... .......... ..........  0% 6.78M 40m58s\n",
      "  3150K .......... .......... .......... .......... ..........  0% 4.96M 40m25s\n",
      "  3200K .......... .......... .......... .......... ..........  0% 5.73M 39m53s\n",
      "  3250K .......... .......... .......... .......... ..........  0% 3.43M 39m26s\n",
      "  3300K .......... .......... .......... .......... ..........  0% 3.26M 38m59s\n",
      "  3350K .......... .......... .......... .......... ..........  0% 2.88M 38m35s\n",
      "  3400K .......... .......... .......... .......... ..........  0% 3.55M 38m9s\n",
      "  3450K .......... .......... .......... .......... ..........  0% 3.44M 37m45s\n",
      "  3500K .......... .......... .......... .......... ..........  0% 3.75M 37m20s\n",
      "  3550K .......... .......... .......... .......... ..........  0% 3.53M 36m57s\n",
      "  3600K .......... .......... .......... .......... ..........  0% 3.44M 36m34s\n",
      "  3650K .......... .......... .......... .......... ..........  0% 2.98M 36m13s\n",
      "  3700K .......... .......... .......... .......... ..........  0% 4.31M 35m50s\n",
      "  3750K .......... .......... .......... .......... ..........  0%  112K 39m18s\n",
      "  3800K .......... .......... .......... .......... ..........  0% 4.85M 38m52s\n",
      "  3850K .......... .......... .......... .......... ..........  0% 95.7K 42m52s\n",
      "  3900K .......... .......... .......... .......... ..........  0% 19.8M 42m20s\n",
      "  3950K .......... .......... .......... .......... ..........  0% 14.4M 41m50s\n",
      "  4000K .......... .......... .......... .......... ..........  0% 18.8M 41m21s\n",
      "  4050K .......... .......... .......... .......... ..........  0% 12.1M 40m52s\n",
      "  4100K .......... .......... .......... .......... ..........  0% 17.6M 40m24s\n",
      "  4150K .......... .......... .......... .......... ..........  0%  251K 41m31s\n",
      "  4200K .......... .......... .......... .......... ..........  0% 15.8M 41m3s\n",
      "  4250K .......... .......... .......... .......... ..........  0% 16.4M 40m35s\n",
      "  4300K .......... .......... .......... .......... ..........  0% 22.6M 40m8s\n",
      "  4350K .......... .......... .......... .......... ..........  0% 12.6M 39m43s\n",
      "  4400K .......... .......... .......... .......... ..........  0% 20.1M 39m17s\n",
      "  4450K .......... .......... .......... .......... ..........  0% 21.2M 38m52s\n",
      "  4500K .......... .......... .......... .......... ..........  0% 20.3M 38m27s\n",
      "  4550K .......... .......... .......... .......... ..........  0%  294K 39m16s\n",
      "  4600K .......... .......... .......... .......... ..........  0% 7.54M 38m54s\n",
      "  4650K .......... .......... .......... .......... ..........  0%  248K 39m55s\n",
      "  4700K .......... .......... .......... .......... ..........  0% 8.91M 39m32s\n",
      "  4750K .......... .......... .......... .......... ..........  0% 11.9M 39m9s\n",
      "  4800K .......... .......... .......... .......... ..........  0% 12.9M 38m47s\n",
      "  4850K .......... .......... .......... .......... ..........  0% 9.22M 38m25s\n",
      "  4900K .......... .......... .......... .......... ..........  0% 18.7M 38m3s\n",
      "  4950K .......... .......... .......... .......... ..........  0% 10.7M 37m42s\n",
      "  5000K .......... .......... .......... .......... ..........  0% 17.9M 37m20s\n",
      "  5050K .......... .......... .......... .......... ..........  0% 11.8M 37m0s\n",
      "  5100K .......... .......... .......... .......... ..........  0% 17.4M 36m39s\n",
      "  5150K .......... .......... .......... .......... ..........  0% 11.8M 36m20s\n",
      "  5200K .......... .......... .......... .......... ..........  0% 14.5M 36m0s\n",
      "  5250K .......... .......... .......... .......... ..........  0% 13.8M 35m41s\n",
      "  5300K .......... .......... .......... .......... ..........  0% 15.4M 35m22s\n",
      "  5350K .......... .......... .......... .......... ..........  0% 9.40M 35m4s\n",
      "  5400K .......... .......... .......... .......... ..........  0% 17.0M 34m46s\n",
      "  5450K .......... .......... .......... .......... ..........  0% 12.8M 34m29s\n",
      "  5500K .......... .......... .......... .......... ..........  0% 20.0M 34m11s\n",
      "  5550K .......... .......... .......... .......... ..........  0% 11.6M 33m54s\n",
      "  5600K .......... .......... .......... .......... ..........  0% 18.6M 33m37s\n",
      "  5650K .......... .......... .......... .......... ..........  0% 17.9M 33m20s\n",
      "  5700K .......... .......... .......... .......... ..........  0% 13.7M 33m4s\n",
      "  5750K .......... .......... .......... .......... ..........  0% 13.6M 32m48s\n",
      "  5800K .......... .......... .......... .......... ..........  0% 16.1M 32m32s\n",
      "  5850K .......... .......... .......... .......... ..........  0% 16.7M 32m16s\n",
      "  5900K .......... .......... .......... .......... ..........  0% 11.5M 32m2s\n",
      "  5950K .......... .......... .......... .......... ..........  0% 16.0M 31m47s\n",
      "  6000K .......... .......... .......... .......... ..........  0% 14.0M 31m32s\n",
      "  6050K .......... .......... .......... .......... ..........  0% 14.4M 31m17s\n",
      "  6100K .......... .......... .......... .......... ..........  0% 14.9M 31m3s\n",
      "  6150K .......... .......... .......... .......... ..........  0%  168K 32m25s\n",
      "  6200K .......... .......... .......... .......... ..........  0% 15.1M 32m10s\n",
      "  6250K .......... .......... .......... .......... ..........  0% 19.4M 31m56s\n",
      "  6300K .......... .......... .......... .......... ..........  0% 16.3M 31m42s\n",
      "  6350K .......... .......... .......... .......... ..........  0% 17.4M 31m28s\n",
      "  6400K .......... .......... .......... .......... ..........  0% 13.5M 31m14s\n",
      "  6450K .......... .......... .......... .......... ..........  0% 18.4M 31m0s\n",
      "  6500K .......... .......... .......... .......... ..........  0% 19.6M 30m47s\n",
      "  6550K .......... .......... .......... .......... ..........  0% 14.5M 30m34s\n",
      "  6600K .......... .......... .......... .......... ..........  0% 17.3M 30m21s\n",
      "  6650K .......... .......... .......... .......... ..........  0% 17.4M 30m8s\n",
      "  6700K .......... .......... .......... .......... ..........  0% 17.0M 29m55s\n",
      "  6750K .......... .......... .......... .......... ..........  0% 13.4M 29m43s\n",
      "  6800K .......... .......... .......... .......... ..........  0%  384K 30m8s\n",
      "  6850K .......... .......... .......... .......... ..........  0%  206K 31m6s\n",
      "  6900K .......... .......... .......... .......... ..........  0%  167K 32m19s\n",
      "  6950K .......... .......... .......... .......... ..........  0% 11.2M 32m7s\n",
      "  7000K .......... .......... .......... .......... ..........  0% 14.4M 31m54s\n",
      "  7050K .......... .......... .......... .......... ..........  0% 14.5M 31m41s\n",
      "  7100K .......... .......... .......... .......... ..........  0%  150K 33m1s\n",
      "  7150K .......... .......... .......... .......... ..........  0% 16.6M 32m48s\n",
      "  7200K .......... .......... .......... .......... ..........  0% 17.6M 32m36s\n",
      "  7250K .......... .......... .......... .......... ..........  0% 1.26M 32m33s\n",
      "  7300K .......... .......... .......... .......... ..........  0% 18.1M 32m20s\n",
      "  7350K .......... .......... .......... .......... ..........  0% 14.6M 32m8s\n",
      "  7400K .......... .......... .......... .......... ..........  0% 17.2M 31m56s\n",
      "  7450K .......... .......... .......... .......... ..........  0% 20.7M 31m44s\n",
      "  7500K .......... .......... .......... .......... ..........  0% 19.7M 31m32s\n",
      "  7550K .......... .......... .......... .......... ..........  0%  305K 32m2s\n",
      "  7600K .......... .......... .......... .......... ..........  0%  231K 32m47s\n",
      "  7650K .......... .......... .......... .......... ..........  0% 1.21M 32m44s\n",
      "  7700K .......... .......... .......... .......... ..........  0% 10.7M 32m33s\n",
      "  7750K .......... .......... .......... .......... ..........  0% 2.07M 32m26s\n",
      "  7800K .......... .......... .......... .......... ..........  0% 5.67M 32m16s\n",
      "  7850K .......... .......... .......... .......... ..........  0% 5.38M 32m6s\n",
      "  7900K .......... .......... .......... .......... ..........  0% 15.5M 31m55s\n",
      "  7950K .......... .......... .......... .......... ..........  0% 18.3M 31m43s\n",
      "  8000K .......... .......... .......... .......... ..........  0% 21.6M 31m32s\n",
      "  8050K .......... .......... .......... .......... ..........  0% 23.7M 31m21s\n",
      "  8100K .......... .......... .......... .......... ..........  0% 23.2M 31m10s\n",
      "  8150K .......... .......... .......... .......... ..........  0% 20.7M 30m59s\n",
      "  8200K .......... .......... .......... .......... ..........  0% 19.2M 30m48s\n",
      "  8250K .......... .......... .......... .......... ..........  0% 21.8M 30m38s\n",
      "  8300K .......... .......... .......... .......... ..........  0% 22.6M 30m27s\n",
      "  8350K .......... .......... .......... .......... ..........  0% 22.3M 30m17s\n",
      "  8400K .......... .......... .......... .......... ..........  0% 20.6M 30m7s\n",
      "  8450K .......... .......... .......... .......... ..........  0% 23.2M 29m56s\n",
      "  8500K .......... .......... .......... .......... ..........  0% 21.4M 29m46s\n",
      "  8550K .......... .......... .......... .......... ..........  0% 19.1M 29m37s\n",
      "  8600K .......... .......... .......... .......... ..........  0% 22.2M 29m27s\n",
      "  8650K .......... .......... .......... .......... ..........  0% 24.4M 29m17s\n",
      "  8700K .......... .......... .......... .......... ..........  0% 26.9M 29m7s\n",
      "  8750K .......... .......... .......... .......... ..........  0% 23.0M 28m58s\n",
      "  8800K .......... .......... .......... .......... ..........  0% 24.9M 28m48s\n",
      "  8850K .......... .......... .......... .......... ..........  0% 23.5M 28m39s\n",
      "  8900K .......... .......... .......... .......... ..........  0% 25.8M 28m30s\n",
      "  8950K .......... .......... .......... .......... ..........  0% 22.3M 28m21s\n",
      "  9000K .......... .......... .......... .......... ..........  0% 26.2M 28m12s\n",
      "  9050K .......... .......... .......... .......... ..........  0% 27.0M 28m3s\n",
      "  9100K .......... .......... .......... .......... ..........  0% 27.2M 27m54s\n",
      "  9150K .......... .......... .......... .......... ..........  0%  941K 27m56s\n",
      "  9200K .......... .......... .......... .......... ..........  0% 15.2M 27m48s\n",
      "  9250K .......... .......... .......... .......... ..........  0% 17.9M 27m40s\n",
      "  9300K .......... .......... .......... .......... ..........  0% 10.5M 27m32s\n",
      "  9350K .......... .......... .......... .......... ..........  0% 3.98M 27m26s\n",
      "  9400K .......... .......... .......... .......... ..........  0% 9.68M 27m18s\n",
      "  9450K .......... .......... .......... .......... ..........  0% 21.3M 27m10s\n",
      "  9500K .......... .......... .......... .......... ..........  0% 2.75M 27m5s\n",
      "  9550K .......... .......... .......... .......... ..........  0% 7.71M 26m58s\n",
      "  9600K .......... .......... .......... .......... ..........  0% 5.77M 26m51s\n",
      "  9650K .......... .......... .......... .......... ..........  0% 5.78M 26m44s\n",
      "  9700K .......... .......... .......... .......... ..........  0% 15.3M 26m37s\n",
      "  9750K .......... .......... .......... .......... ..........  0% 13.4M 26m29s\n",
      "  9800K .......... .......... .......... .......... ..........  0% 13.5M 26m22s\n",
      "  9850K .......... .......... .......... .......... ..........  0% 13.0M 26m15s\n",
      "  9900K .......... .......... .......... .......... ..........  0% 18.4M 26m7s\n",
      "  9950K .......... .......... .......... .......... ..........  0% 11.1M 26m0s\n",
      " 10000K .......... .......... .......... .......... ..........  0% 20.6M 25m53s\n",
      " 10050K .......... .......... .......... .......... ..........  0% 20.6M 25m46s\n",
      " 10100K .......... .......... .......... .......... ..........  0% 12.9M 25m39s\n",
      " 10150K .......... .......... .......... .......... ..........  0% 14.4M 25m32s\n",
      " 10200K .......... .......... .......... .......... ..........  0% 11.6M 25m25s\n",
      " 10250K .......... .......... .......... .......... ..........  0% 13.8M 25m18s\n",
      " 10300K .......... .......... .......... .......... ..........  0% 6.25M 25m13s\n",
      " 10350K .......... .......... .......... .......... ..........  0% 5.97M 25m7s\n",
      " 10400K .......... .......... .......... .......... ..........  0%  582K 25m16s\n",
      " 10450K .......... .......... .......... .......... ..........  0% 4.53M 25m11s\n",
      " 10500K .......... .......... .......... .......... ..........  0% 4.67M 25m6s\n",
      " 10550K .......... .......... .......... .......... ..........  0% 3.65M 25m1s\n",
      " 10600K .......... .......... .......... .......... ..........  0% 4.35M 24m56s\n",
      " 10650K .......... .......... .......... .......... ..........  0% 5.44M 24m51s\n",
      " 10700K .......... .......... .......... .......... ..........  0% 5.71M 24m45s\n",
      " 10750K .......... .......... .......... .......... ..........  0% 5.63M 24m40s\n",
      " 10800K .......... .......... .......... .......... ..........  0% 5.33M 24m35s\n",
      " 10850K .......... .......... .......... .......... ..........  0% 5.33M 24m30s\n",
      " 10900K .......... .......... .......... .......... ..........  0% 6.25M 24m24s\n",
      " 10950K .......... .......... .......... .......... ..........  0% 4.35M 24m20s\n",
      " 11000K .......... .......... .......... .......... ..........  0% 6.23M 24m15s\n",
      " 11050K .......... .......... .......... .......... ..........  0% 6.33M 24m9s\n",
      " 11100K .......... .......... .......... .......... ..........  0%  114K 25m22s\n",
      " 11150K .......... .......... .......... .......... ..........  0% 9.54M 25m16s\n",
      " 11200K .......... .......... .......... .......... ..........  0% 4.94M 25m11s\n",
      " 11250K .......... .......... .......... .......... ..........  0% 6.69M 25m6s\n",
      " 11300K .......... .......... .......... .......... ..........  0% 11.1M 25m0s\n",
      " 11350K .......... .......... .......... .......... ..........  0% 7.39M 24m54s\n",
      " 11400K .......... .......... .......... .......... ..........  0% 16.1M 24m48s\n",
      " 11450K .......... .......... .......... .......... ..........  0% 14.4M 24m42s\n",
      " 11500K .......... .......... .......... .......... ..........  0%  958K 24m45s\n",
      " 11550K .......... .......... .......... .......... ..........  0% 10.3M 24m39s\n",
      " 11600K .......... .......... .......... .......... ..........  0% 20.9M 24m33s\n",
      " 11650K .......... .......... .......... .......... ..........  0% 23.0M 24m27s\n",
      " 11700K .......... .......... .......... .......... ..........  0% 26.0M 24m21s\n",
      " 11750K .......... .......... .......... .......... ..........  0% 31.6M 24m15s\n",
      " 11800K .......... .......... .......... .......... ..........  0%  482K 24m27s\n",
      " 11850K .......... .......... .......... .......... ..........  0% 4.70M 24m22s\n",
      " 11900K .......... .......... .......... .......... ..........  0% 23.7M 24m16s\n",
      " 11950K .......... .......... .......... .......... ..........  0% 31.5M 24m11s\n",
      " 12000K .......... .......... .......... .......... ..........  0% 37.2M 24m5s\n",
      " 12050K .......... .......... .......... .......... ..........  0% 39.8M 23m59s\n",
      " 12100K .......... .......... .......... .......... ..........  0% 35.4M 23m53s\n",
      " 12150K .......... .......... .......... .......... ..........  0% 20.9M 23m48s\n",
      " 12200K .......... .......... .......... .......... ..........  0% 30.1M 23m42s\n",
      " 12250K .......... .......... .......... .......... ..........  0% 32.7M 23m37s\n",
      " 12300K .......... .......... .......... .......... ..........  0% 31.0M 23m31s\n",
      " 12350K .......... .......... .......... .......... ..........  0% 29.8M 23m26s\n",
      " 12400K .......... .......... .......... .......... ..........  0% 35.4M 23m20s\n",
      " 12450K .......... .......... .......... .......... ..........  0% 31.0M 23m15s\n",
      " 12500K .......... .......... .......... .......... ..........  0% 31.4M 23m9s\n",
      " 12550K .......... .......... .......... .......... ..........  0% 27.0M 23m4s\n",
      " 12600K .......... .......... .......... .......... ..........  0% 29.4M 22m59s\n",
      " 12650K .......... .......... .......... .......... ..........  0% 31.6M 22m54s\n",
      " 12700K .......... .......... .......... .......... ..........  0% 30.9M 22m49s\n",
      " 12750K .......... .......... .......... .......... ..........  0% 28.3M 22m43s\n",
      " 12800K .......... .......... .......... .......... ..........  0% 22.7M 22m38s\n",
      " 12850K .......... .......... .......... .......... ..........  0% 33.2M 22m33s\n",
      " 12900K .......... .......... .......... .......... ..........  0% 30.5M 22m28s\n",
      " 12950K .......... .......... .......... .......... ..........  0% 27.6M 22m23s\n",
      " 13000K .......... .......... .......... .......... ..........  0% 33.8M 22m18s\n",
      " 13050K .......... .......... .......... .......... ..........  0% 28.1M 22m14s\n",
      " 13100K .......... .......... .......... .......... ..........  0% 31.5M 22m9s\n",
      " 13150K .......... .......... .......... .......... ..........  0% 28.0M 22m4s\n",
      " 13200K .......... .......... .......... .......... ..........  0% 32.3M 21m59s\n",
      " 13250K .......... .......... .......... .......... ..........  0% 26.2M 21m54s\n",
      " 13300K .......... .......... .......... .......... ..........  0% 38.8M 21m50s\n",
      " 13350K .......... .......... .......... .......... ..........  0% 4.48M 21m46s\n",
      " 13400K .......... .......... .......... .......... ..........  0% 4.24M 21m43s\n",
      " 13450K .......... .......... .......... .......... ..........  0% 4.43M 21m40s\n",
      " 13500K .......... .......... .......... .......... ..........  0% 4.54M 21m37s\n",
      " 13550K .......... .......... .......... .......... ..........  0% 3.93M 21m34s\n",
      " 13600K .......... .......... .......... .......... ..........  0% 3.62M 21m31s\n",
      " 13650K .......... .......... .......... .......... ..........  0% 3.61M 21m28s\n",
      " 13700K .......... .......... .......... .......... ..........  0% 3.43M 21m25s\n",
      " 13750K .......... .......... .......... .......... ..........  0% 2.60M 21m24s\n",
      " 13800K .......... .......... .......... .......... ..........  0% 3.97M 21m21s\n",
      " 13850K .......... .......... .......... .......... ..........  0% 3.06M 21m18s\n",
      " 13900K .......... .......... .......... .......... ..........  0% 3.79M 21m16s\n",
      " 13950K .......... .......... .......... .......... ..........  0% 3.26M 21m13s\n",
      " 14000K .......... .......... .......... .......... ..........  0% 3.86M 21m10s\n",
      " 14050K .......... .......... .......... .......... ..........  0% 3.67M 21m8s\n",
      " 14100K .......... .......... .......... .......... ..........  0% 3.23M 21m5s\n",
      " 14150K .......... .......... .......... .......... ..........  0% 2.65M 21m3s\n",
      " 14200K .......... .......... .......... .......... ..........  0% 3.42M 21m1s\n",
      " 14250K .......... .......... .......... .......... ..........  0% 3.78M 20m58s\n",
      " 14300K .......... .......... .......... .......... ..........  0% 4.03M 20m56s\n",
      " 14350K .......... .......... .......... .......... ..........  0% 2.81M 20m54s\n",
      " 14400K .......... .......... .......... .......... ..........  0% 3.08M 20m51s\n",
      " 14450K .......... .......... .......... .......... ..........  0% 3.74M 20m49s\n",
      " 14500K .......... .......... .......... .......... ..........  0% 3.59M 20m46s\n",
      " 14550K .......... .......... .......... .......... ..........  0% 3.46M 20m44s\n",
      " 14600K .......... .......... .......... .......... ..........  0% 3.31M 20m42s\n",
      " 14650K .......... .......... .......... .......... ..........  0%  924K 20m45s\n",
      " 14700K .......... .......... .......... .......... ..........  0% 3.91M 20m42s\n",
      " 14750K .......... .......... .......... .......... ..........  0% 3.81M 20m40s\n",
      " 14800K .......... .......... .......... .......... ..........  0%  214K 21m7s\n",
      " 14850K .......... .......... .......... .......... ..........  0% 4.77M 21m4s\n",
      " 14900K .......... .......... .......... .......... ..........  0%  226K 21m30s\n",
      " 14950K .......... .......... .......... .......... ..........  0% 28.4M 21m25s\n",
      " 15000K .......... .......... .......... .......... ..........  0% 26.1M 21m21s\n",
      " 15050K .......... .......... .......... .......... ..........  0% 1.66M 21m21s\n",
      " 15100K .......... .......... .......... .......... ..........  0% 4.24M 21m18s\n",
      " 15150K .......... .......... .......... .......... ..........  0% 17.0M 21m14s\n",
      " 15200K .......... .......... .......... .......... ..........  0% 21.3M 21m11s\n",
      " 15250K .......... .......... .......... .......... ..........  0% 26.2M 21m7s\n",
      " 15300K .......... .......... .......... .......... ..........  0% 23.0M 21m3s\n",
      " 15350K .......... .......... .......... .......... ..........  0%  645K 21m9s\n",
      " 15400K .......... .......... .......... .......... ..........  0% 27.9M 21m5s\n",
      " 15450K .......... .......... .......... .......... ..........  0% 23.4M 21m1s\n",
      " 15500K .......... .......... .......... .......... ..........  0% 30.1M 20m57s\n",
      " 15550K .......... .......... .......... .......... ..........  0% 20.4M 20m53s\n",
      " 15600K .......... .......... .......... .......... ..........  0% 30.0M 20m49s\n",
      " 15650K .......... .......... .......... .......... ..........  0% 33.2M 20m46s\n",
      " 15700K .......... .......... .......... .......... ..........  0% 34.8M 20m42s\n",
      " 15750K .......... .......... .......... .......... ..........  0% 26.8M 20m38s\n",
      " 15800K .......... .......... .......... .......... ..........  0% 35.6M 20m34s\n",
      " 15850K .......... .......... .......... .......... ..........  0% 29.5M 20m31s\n",
      " 15900K .......... .......... .......... .......... ..........  0% 33.9M 20m27s\n",
      " 15950K .......... .......... .......... .......... ..........  0% 23.1M 20m23s\n",
      " 16000K .......... .......... .......... .......... ..........  0% 26.2M 20m20s\n",
      " 16050K .......... .......... .......... .......... ..........  0% 16.2M 20m16s\n",
      " 16100K .......... .......... .......... .......... ..........  0% 35.7M 20m13s\n",
      " 16150K .......... .......... .......... .......... ..........  0% 33.3M 20m9s\n",
      " 16200K .......... .......... .......... .......... ..........  0% 40.4M 20m5s\n",
      " 16250K .......... .......... .......... .......... ..........  0% 29.1M 20m2s\n",
      " 16300K .......... .......... .......... .......... ..........  0% 30.8M 19m58s\n",
      " 16350K .......... .......... .......... .......... ..........  0% 21.5M 19m55s\n",
      " 16400K .......... .......... .......... .......... ..........  0% 35.4M 19m52s\n",
      " 16450K .......... .......... .......... .......... ..........  0% 30.6M 19m48s\n",
      " 16500K .......... .......... .......... .......... ..........  0% 20.7M 19m45s\n",
      " 16550K .......... .......... .......... .......... ..........  0% 21.2M 19m41s\n",
      " 16600K .......... .......... .......... .......... ..........  0% 21.3M 19m38s\n",
      " 16650K .......... .......... .......... .......... ..........  0% 31.5M 19m35s\n",
      " 16700K .......... .......... .......... .......... ..........  0% 34.9M 19m31s\n",
      " 16750K .......... .......... .......... .......... ..........  0% 22.1M 19m28s\n",
      " 16800K .......... .......... .......... .......... ..........  0% 27.6M 19m25s\n",
      " 16850K .......... .......... .......... .......... ..........  0% 28.8M 19m22s\n",
      " 16900K .......... .......... .......... .......... ..........  0% 24.4M 19m18s\n",
      " 16950K .......... .......... .......... .......... ..........  0% 26.3M 19m15s\n",
      " 17000K .......... .......... .......... .......... ..........  0% 5.42M 19m13s\n",
      " 17050K .......... .......... .......... .......... ..........  0% 5.01M 19m11s\n",
      " 17100K .......... .......... .......... .......... ..........  0% 4.90M 19m8s\n",
      " 17150K .......... .......... .......... .......... ..........  0% 4.97M 19m6s\n",
      " 17200K .......... .......... .......... .......... ..........  0% 4.39M 19m4s\n",
      " 17250K .......... .......... .......... .......... ..........  0% 4.97M 19m2s\n",
      " 17300K .......... .......... .......... .......... ..........  0% 4.37M 19m0s\n",
      " 17350K .......... .......... .......... .......... ..........  0% 3.15M 18m58s\n",
      " 17400K .......... .......... .......... .......... ..........  0% 3.20M 18m57s\n",
      " 17450K .......... .......... .......... .......... ..........  0% 3.59M 18m55s\n",
      " 17500K .......... .......... .......... .......... ..........  0% 3.59M 18m53s\n",
      " 17550K .......... .......... .......... .......... ..........  0% 3.53M 18m52s\n",
      " 17600K .......... .......... .......... .......... ..........  0% 3.51M 18m50s\n",
      " 17650K .......... .......... .......... .......... ..........  0% 3.32M 18m48s\n",
      " 17700K .......... .......... .......... .......... ..........  0% 3.83M 18m47s\n",
      " 17750K .......... .......... .......... .......... ..........  0% 2.53M 18m46s\n",
      " 17800K .......... .......... .......... .......... ..........  0% 3.55M 18m44s\n",
      " 17850K .......... .......... .......... .......... ..........  0% 3.28M 18m42s\n",
      " 17900K .......... .......... .......... .......... ..........  0% 3.98M 18m41s\n",
      " 17950K .......... .......... .......... .......... ..........  0% 3.45M 18m39s\n",
      " 18000K .......... .......... .......... .......... ..........  0% 3.35M 18m38s\n",
      " 18050K .......... .......... .......... .......... ..........  0% 3.49M 18m36s\n",
      " 18100K .......... .......... .......... .......... ..........  0% 3.75M 18m34s\n",
      " 18150K .......... .......... .......... .......... ..........  0% 2.59M 18m33s\n",
      " 18200K .......... .......... .......... .......... ..........  0% 3.15M 18m32s\n",
      " 18250K .......... .......... .......... .......... ..........  0% 4.04M 18m30s\n",
      " 18300K .......... .......... .......... .......... ..........  0% 3.45M 18m29s\n",
      " 18350K .......... .......... .......... .......... ..........  0% 3.49M 18m27s\n",
      " 18400K .......... .......... .......... .......... ..........  0% 3.68M 18m26s\n",
      " 18450K .......... .......... .......... .......... ..........  0% 3.32M 18m24s\n",
      " 18500K .......... .......... .......... .......... ..........  0% 3.61M 18m23s\n",
      " 18550K .......... .......... .......... .......... ..........  0% 2.60M 18m22s\n",
      " 18600K .......... .......... .......... .......... ..........  0% 3.73M 18m20s\n",
      " 18650K .......... .......... .......... .......... ..........  0% 3.59M 18m19s\n",
      " 18700K .......... .......... .......... .......... ..........  0% 3.41M 18m17s\n",
      " 18750K .......... .......... .......... .......... ..........  0% 3.34M 18m16s\n",
      " 18800K .......... .......... .......... .......... ..........  0% 3.44M 18m14s\n",
      " 18850K .......... .......... .......... .......... ..........  0%  157K 18m45s\n",
      " 18900K .......... .......... .......... .......... ..........  0% 6.36M 18m43s\n",
      " 18950K .......... .......... .......... .......... ..........  0%  232K 19m2s\n",
      " 19000K .......... .......... .......... .......... ..........  0% 6.53M 19m0s\n",
      " 19050K .......... .......... .......... .......... ..........  0% 15.9M 18m58s\n",
      " 19100K .......... .......... .......... .......... ..........  0% 16.8M 18m55s\n",
      " 19150K .......... .......... .......... .......... ..........  0% 2.06M 18m54s\n",
      " 19200K .......... .......... .......... .......... ..........  0% 5.07M 18m52s\n",
      " 19250K .......... .......... .......... .......... ..........  0% 18.2M 18m50s\n",
      " 19300K .......... .......... .......... .......... ..........  0% 2.53M 18m49s\n",
      " 19350K .......... .......... .......... .......... ..........  0% 13.2M 18m46s\n",
      " 19400K .......... .......... .......... .......... ..........  0% 19.0M 18m44s\n",
      " 19450K .......... .......... .......... .......... ..........  0% 19.3M 18m41s\n",
      " 19500K .......... .......... .......... .......... ..........  0% 20.8M 18m38s\n",
      " 19550K .......... .......... .......... .......... ..........  0% 16.9M 18m36s\n",
      " 19600K .......... .......... .......... .......... ..........  0% 14.4M 18m33s\n",
      " 19650K .......... .......... .......... .......... ..........  0% 23.0M 18m30s\n",
      " 19700K .......... .......... .......... .......... ..........  0% 19.9M 18m28s\n",
      " 19750K .......... .......... .......... .......... ..........  0% 16.5M 18m25s\n",
      " 19800K .......... .......... .......... .......... ..........  0% 18.9M 18m23s\n",
      " 19850K .......... .......... .......... .......... ..........  0% 20.4M 18m20s\n",
      " 19900K .......... .......... .......... .......... ..........  0% 25.9M 18m18s\n",
      " 19950K .......... .......... .......... .......... ..........  0% 36.6M 18m15s\n",
      " 20000K .......... .......... .......... .......... ..........  0% 27.1M 18m12s\n",
      " 20050K .......... .......... .......... .......... ..........  0% 30.8M 18m10s\n",
      " 20100K .......... .......... .......... .......... ..........  0% 39.2M 18m7s\n",
      " 20150K .......... .......... .......... .......... ..........  1% 26.7M 18m5s\n",
      " 20200K .......... .......... .......... .......... ..........  1% 36.4M 18m2s\n",
      " 20250K .......... .......... .......... .......... ..........  1% 43.2M 18m0s\n",
      " 20300K .......... .......... .......... .......... ..........  1% 24.5M 17m57s\n",
      " 20350K .......... .......... .......... .......... ..........  1% 8.11M 17m55s\n",
      " 20400K .......... .......... .......... .......... ..........  1% 7.71M 17m53s\n",
      " 20450K .......... .......... .......... .......... ..........  1% 21.3M 17m51s\n",
      " 20500K .......... .......... .......... .......... ..........  1% 36.2M 17m48s\n",
      " 20550K .......... .......... .......... .......... ..........  1% 28.3M 17m46s\n",
      " 20600K .......... .......... .......... .......... ..........  1% 6.18M 17m44s\n",
      " 20650K .......... .......... .......... .......... ..........  1% 3.64M 17m42s\n",
      " 20700K .......... .......... .......... .......... ..........  1% 3.33M 17m41s\n",
      " 20750K .......... .......... .......... .......... ..........  1% 3.58M 17m40s\n",
      " 20800K .......... .......... .......... .......... ..........  1% 3.59M 17m39s\n",
      " 20850K .......... .......... .......... .......... ..........  1% 3.30M 17m38s\n",
      " 20900K .......... .......... .......... .......... ..........  1% 3.62M 17m36s\n",
      " 20950K .......... .......... .......... .......... ..........  1% 2.69M 17m35s\n",
      " 21000K .......... .......... .......... .......... ..........  1% 3.45M 17m34s\n",
      " 21050K .......... .......... .......... .......... ..........  1% 3.65M 17m33s\n",
      " 21100K .......... .......... .......... .......... ..........  1% 3.28M 17m32s\n",
      " 21150K .......... .......... .......... .......... ..........  1% 3.44M 17m31s\n",
      " 21200K .......... .......... .......... .......... ..........  1% 3.55M 17m30s\n",
      " 21250K .......... .......... .......... .......... ..........  1% 3.70M 17m28s\n",
      " 21300K .......... .......... .......... .......... ..........  1% 3.41M 17m27s\n",
      " 21350K .......... .......... .......... .......... ..........  1% 2.71M 17m26s\n",
      " 21400K .......... .......... .......... .......... ..........  1% 3.22M 17m25s\n",
      " 21450K .......... .......... .......... .......... ..........  1% 3.97M 17m24s\n",
      " 21500K .......... .......... .......... .......... ..........  1% 3.48M 17m23s\n",
      " 21550K .......... .......... .......... .......... ..........  1% 3.18M 17m22s\n",
      " 21600K .......... .......... .......... .......... ..........  1% 3.71M 17m21s\n",
      " 21650K .......... .......... .......... .......... ..........  1% 3.47M 17m19s\n",
      " 21700K .......... .......... .......... .......... ..........  1% 3.58M 17m18s\n",
      " 21750K .......... .......... .......... .......... ..........  1% 2.54M 17m18s\n",
      " 21800K .......... .......... .......... .......... ..........  1% 3.54M 17m16s\n",
      " 21850K .......... .......... .......... .......... ..........  1% 3.85M 17m15s\n",
      " 21900K .......... .......... .......... .......... ..........  1% 3.26M 17m14s\n",
      " 21950K .......... .......... .......... .......... ..........  1% 3.26M 17m13s\n",
      " 22000K .......... .......... .......... .......... ..........  1% 3.69M 17m12s\n",
      " 22050K .......... .......... .......... .......... ..........  1% 3.42M 17m11s\n",
      " 22100K .......... .......... .......... .......... ..........  1% 3.87M 17m10s\n",
      " 22150K .......... .......... .......... .......... ..........  1% 2.52M 17m9s\n",
      " 22200K .......... .......... .......... .......... ..........  1% 95.8K 17m54s\n",
      " 22250K .......... .......... .......... .......... ..........  1% 34.3M 17m51s\n",
      " 22300K .......... .......... .......... .......... ..........  1% 32.3M 17m49s\n",
      " 22350K .......... .......... .......... .......... ..........  1% 33.6M 17m47s\n",
      " 22400K .......... .......... .......... .......... ..........  1% 39.6M 17m44s\n",
      " 22450K .......... .......... .......... .......... ..........  1% 37.6M 17m42s\n",
      " 22500K .......... .......... .......... .......... ..........  1% 24.2M 17m40s\n",
      " 22550K .......... .......... .......... .......... ..........  1% 27.6M 17m38s\n",
      " 22600K .......... .......... .......... .......... ..........  1%  687K 17m42s\n",
      " 22650K .......... .......... .......... .......... ..........  1% 33.3M 17m39s\n",
      " 22700K .......... .......... .......... .......... ..........  1% 24.7M 17m37s\n",
      " 22750K .......... .......... .......... .......... ..........  1% 24.8M 17m35s\n",
      " 22800K .......... .......... .......... .......... ..........  1% 1.32M 17m36s\n",
      " 22850K .......... .......... .......... .......... ..........  1% 33.2M 17m34s\n",
      " 22900K .......... .......... .......... .......... ..........  1% 28.0M 17m32s\n",
      " 22950K .......... .......... .......... .......... ..........  1% 25.5M 17m30s\n",
      " 23000K .......... .......... .......... .......... ..........  1% 39.5M 17m27s\n",
      " 23050K .......... .......... .......... .......... ..........  1%  600K 17m32s\n",
      " 23100K .......... .......... .......... .......... ..........  1% 28.8M 17m30s\n",
      " 23150K .......... .......... .......... .......... ..........  1% 34.3M 17m28s\n",
      " 23200K .......... .......... .......... .......... ..........  1% 38.8M 17m26s\n",
      " 23250K .......... .......... .......... .......... ..........  1% 38.6M 17m24s\n",
      " 23300K .......... .......... .......... .......... ..........  1% 25.7M 17m21s\n",
      " 23350K .......... .......... .......... .......... ..........  1% 29.6M 17m19s\n",
      " 23400K .......... .......... .......... .......... ..........  1% 38.9M 17m17s\n",
      " 23450K .......... .......... .......... .......... ..........  1% 35.9M 17m15s\n",
      " 23500K .......... .......... .......... .......... ..........  1% 38.3M 17m13s\n",
      " 23550K .......... .......... .......... .......... ..........  1% 30.9M 17m11s\n",
      " 23600K .......... .......... .......... .......... ..........  1% 34.1M 17m9s\n",
      " 23650K .......... .......... .......... .......... ..........  1% 41.7M 17m7s\n",
      " 23700K .......... .......... .......... .......... ..........  1% 40.1M 17m5s\n",
      " 23750K .......... .......... .......... .......... ..........  1% 31.0M 17m3s\n",
      " 23800K .......... .......... .......... .......... ..........  1% 36.0M 17m1s\n",
      " 23850K .......... .......... .......... .......... ..........  1% 33.8M 16m58s\n",
      " 23900K .......... .......... .......... .......... ..........  1% 42.8M 16m56s\n",
      " 23950K .......... .......... .......... .......... ..........  1% 36.5M 16m54s\n",
      " 24000K .......... .......... .......... .......... ..........  1% 40.0M 16m52s\n",
      " 24050K .......... .......... .......... .......... ..........  1% 30.5M 16m50s\n",
      " 24100K .......... .......... .......... .......... ..........  1% 33.7M 16m48s\n",
      " 24150K .......... .......... .......... .......... ..........  1% 26.1M 16m46s\n",
      " 24200K .......... .......... .......... .......... ..........  1% 42.2M 16m44s\n",
      " 24250K .......... .......... .......... .......... ..........  1% 3.95M 16m43s\n",
      " 24300K .......... .......... .......... .......... ..........  1% 3.18M 16m43s\n",
      " 24350K .......... .......... .......... .......... ..........  1% 3.30M 16m42s\n",
      " 24400K .......... .......... .......... .......... ..........  1% 3.33M 16m41s\n",
      " 24450K .......... .......... .......... .......... ..........  1% 3.30M 16m40s\n",
      " 24500K .......... .......... .......... .......... ..........  1% 3.20M 16m39s\n",
      " 24550K .......... .......... .......... .......... ..........  1% 2.43M 16m39s\n",
      " 24600K .......... .......... .......... .......... ..........  1% 3.13M 16m38s\n",
      " 24650K .......... .......... .......... .......... ..........  1% 3.40M 16m37s\n",
      " 24700K .......... .......... .......... .......... ..........  1% 3.36M 16m36s\n",
      " 24750K .......... .......... .......... .......... ..........  1% 3.15M 16m35s\n",
      " 24800K .......... .......... .......... .......... ..........  1% 3.27M 16m34s\n",
      " 24850K .......... .......... .......... .......... ..........  1% 3.04M 16m34s\n",
      " 24900K .......... .......... .......... .......... ..........  1% 3.04M 16m33s\n",
      " 24950K .......... .......... .......... .......... ..........  1% 2.35M 16m33s\n",
      " 25000K .......... .......... .......... .......... ..........  1% 2.91M 16m32s\n",
      " 25050K .......... .......... .......... .......... ..........  1% 2.81M 16m31s\n",
      " 25100K .......... .......... .......... .......... ..........  1% 3.47M 16m30s\n",
      " 25150K .......... .......... .......... .......... ..........  1% 2.93M 16m30s\n",
      " 25200K .......... .......... .......... .......... ..........  1% 2.67M 16m29s\n",
      " 25250K .......... .......... .......... .......... ..........  1% 2.71M 16m29s\n",
      " 25300K .......... .......... .......... .......... ..........  1% 2.95M 16m28s\n",
      " 25350K .......... .......... .......... .......... ..........  1% 2.20M 16m28s\n",
      " 25400K .......... .......... .......... .......... ..........  1% 2.83M 16m27s\n",
      " 25450K .......... .......... .......... .......... ..........  1%  214K 16m43s\n",
      " 25500K .......... .......... .......... .......... ..........  1% 2.97M 16m43s\n",
      " 25550K .......... .......... .......... .......... ..........  1% 6.88M 16m41s\n",
      " 25600K .......... .......... .......... .......... ..........  1%  121K 17m12s\n",
      " 25650K .......... .......... .......... .......... ..........  1% 8.18M 17m10s\n",
      " 25700K .......... .......... .......... .......... ..........  1% 16.8M 17m8s\n",
      " 25750K .......... .......... .......... .......... ..........  1% 14.5M 17m6s\n",
      " 25800K .......... .......... .......... .......... ..........  1% 35.3M 17m5s\n",
      " 25850K .......... .......... .......... .......... ..........  1% 26.9M 17m3s\n",
      " 25900K .......... .......... .......... .......... ..........  1% 21.1M 17m1s\n",
      " 25950K .......... .......... .......... .......... ..........  1% 26.6M 16m59s\n",
      " 26000K .......... .......... .......... .......... ..........  1% 33.8M 16m57s\n",
      " 26050K .......... .......... .......... .......... ..........  1% 23.7M 16m55s\n",
      " 26100K .......... .......... .......... .......... ..........  1% 28.2M 16m53s\n",
      " 26150K .......... .......... .......... .......... ..........  1% 17.0M 16m52s\n",
      " 26200K .......... .......... .......... .......... ..........  1% 17.5M 16m50s\n",
      " 26250K .......... .......... .......... .......... ..........  1% 26.1M 16m48s\n",
      " 26300K .......... .......... .......... .......... ..........  1% 5.68M 16m47s\n",
      " 26350K .......... .......... .......... .......... ..........  1% 3.31M 16m46s\n",
      " 26400K .......... .......... .......... .......... ..........  1% 3.46M 16m45s\n",
      " 26450K .......... .......... .......... .......... ..........  1% 3.51M 16m44s\n",
      " 26500K .......... .......... .......... .......... ..........  1%  543K 16m49s\n",
      " 26550K .......... .......... .......... .......... ..........  1% 2.33M 16m49s\n",
      " 26600K .......... .......... .......... .......... ..........  1% 3.08M 16m48s\n",
      " 26650K .......... .......... .......... .......... ..........  1% 3.15M 16m47s\n",
      " 26700K .......... .......... .......... .......... ..........  1% 2.78M 16m47s\n",
      " 26750K .......... .......... .......... .......... ..........  1% 2.95M 16m46s\n",
      " 26800K .......... .......... .......... .......... ..........  1% 2.80M 16m46s\n",
      " 26850K .......... .......... .......... .......... ..........  1% 2.81M 16m45s\n",
      " 26900K .......... .......... .......... .......... ..........  1% 2.78M 16m44s\n",
      " 26950K .......... .......... .......... .......... ..........  1% 2.29M 16m44s\n",
      " 27000K .......... .......... .......... .......... ..........  1% 1.21M 16m45s\n",
      " 27050K .......... .......... .......... .......... ..........  1% 2.70M 16m45s\n",
      " 27100K .......... .......... .......... .......... ..........  1% 2.82M 16m44s\n",
      " 27150K .......... .......... .......... .......... ..........  1% 2.62M 16m43s\n",
      " 27200K .......... .......... .......... .......... ..........  1% 2.92M 16m43s\n",
      " 27250K .......... .......... .......... .......... ..........  1% 2.85M 16m42s\n",
      " 27300K .......... .......... .......... .......... ..........  1% 2.57M 16m42s\n",
      " 27350K .......... .......... .......... .......... ..........  1% 2.15M 16m42s\n",
      " 27400K .......... .......... .......... .......... ..........  1%  221K 16m56s\n",
      " 27450K .......... .......... .......... .......... ..........  1% 3.41M 16m55s\n",
      " 27500K .......... .......... .......... .......... ..........  1% 2.99M 16m55s\n",
      " 27550K .......... .......... .......... .......... ..........  1% 5.65M 16m53s\n",
      " 27600K .......... .......... .......... .......... ..........  1% 2.04M 16m53s\n",
      " 27650K .......... .......... .......... .......... ..........  1%  227K 17m7s\n",
      " 27700K .......... .......... .......... .......... ..........  1% 5.96M 17m6s\n",
      " 27750K .......... .......... .......... .......... ..........  1% 16.1M 17m4s\n",
      " 27800K .......... .......... .......... .......... ..........  1% 18.2M 17m3s\n",
      " 27850K .......... .......... .......... .......... ..........  1% 1.14M 17m4s\n",
      " 27900K .......... .......... .......... .......... ..........  1% 5.49M 17m2s\n",
      " 27950K .......... .......... .......... .......... ..........  1% 17.8M 17m1s\n",
      " 28000K .......... .......... .......... .......... ..........  1% 19.3M 16m59s\n",
      " 28050K .......... .......... .......... .......... ..........  1% 21.5M 16m57s\n",
      " 28100K .......... .......... .......... .......... ..........  1% 20.6M 16m56s\n",
      " 28150K .......... .......... .......... .......... ..........  1% 15.1M 16m54s\n",
      " 28200K .......... .......... .......... .......... ..........  1% 22.7M 16m53s\n",
      " 28250K .......... .......... .......... .......... ..........  1% 17.9M 16m51s\n",
      " 28300K .......... .......... .......... .......... ..........  1% 18.4M 16m49s\n",
      " 28350K .......... .......... .......... .......... ..........  1% 16.6M 16m48s\n",
      " 28400K .......... .......... .......... .......... ..........  1% 16.9M 16m46s\n",
      " 28450K .......... .......... .......... .......... ..........  1% 17.6M 16m45s\n",
      " 28500K .......... .......... .......... .......... ..........  1% 11.2M 16m43s\n",
      " 28550K .......... .......... .......... .......... ..........  1% 18.9M 16m41s\n",
      " 28600K .......... .......... .......... .......... ..........  1% 17.4M 16m40s\n",
      " 28650K .......... .......... .......... .......... ..........  1% 15.7M 16m38s\n",
      " 28700K .......... .......... .......... .......... ..........  1% 16.5M 16m37s\n",
      " 28750K .......... .......... .......... .......... ..........  1% 16.1M 16m35s\n",
      " 28800K .......... .......... .......... .......... ..........  1%  661K 16m39s\n",
      " 28850K .......... .......... .......... .......... ..........  1% 16.2M 16m37s\n",
      " 28900K .......... .......... .......... .......... ..........  1% 19.4M 16m36s\n",
      " 28950K .......... .......... .......... .......... ..........  1% 16.7M 16m34s\n",
      " 29000K .......... .......... .......... .......... ..........  1% 20.3M 16m32s\n",
      " 29050K .......... .......... .......... .......... ..........  1% 18.2M 16m31s\n",
      " 29100K .......... .......... .......... .......... ..........  1% 14.4M 16m29s\n",
      " 29150K .......... .......... .......... .......... ..........  1% 16.0M 16m28s\n",
      " 29200K .......... .......... .......... .......... ..........  1% 19.7M 16m26s\n",
      " 29250K .......... .......... .......... .......... ..........  1% 17.8M 16m25s\n",
      " 29300K .......... .......... .......... .......... ..........  1% 18.0M 16m23s\n",
      " 29350K .......... .......... .......... .......... ..........  1% 17.4M 16m22s\n",
      " 29400K .......... .......... .......... .......... ..........  1% 18.7M 16m20s\n",
      " 29450K .......... .......... .......... .......... ..........  1% 20.1M 16m19s\n",
      " 29500K .......... .......... .......... .......... ..........  1% 15.8M 16m17s\n",
      " 29550K .......... .......... .......... .......... ..........  1% 13.3M 16m16s\n",
      " 29600K .......... .......... .......... .......... ..........  1% 7.60M 16m15s\n",
      " 29650K .......... .......... .......... .......... ..........  1% 2.94M 16m14s\n",
      " 29700K .......... .......... .......... .......... ..........  1% 3.35M 16m13s\n",
      " 29750K .......... .......... .......... .......... ..........  1% 3.22M 16m13s\n",
      " 29800K .......... .......... .......... .......... ..........  1% 3.03M 16m12s\n",
      " 29850K .......... .......... .......... .......... ..........  1% 2.95M 16m12s\n",
      " 29900K .......... .......... .......... .......... ..........  1% 2.94M 16m11s\n",
      " 29950K .......... .......... .......... .......... ..........  1% 2.54M 16m11s\n",
      " 30000K .......... .......... .......... .......... ..........  1% 2.97M 16m10s\n",
      " 30050K .......... .......... .......... .......... ..........  1% 3.11M 16m10s\n",
      " 30100K .......... .......... .......... .......... ..........  1% 2.98M 16m9s\n",
      " 30150K .......... .......... .......... .......... ..........  1% 2.74M 16m9s\n",
      " 30200K .......... .......... .......... .......... ..........  1% 3.05M 16m8s\n",
      " 30250K .......... .......... .......... .......... ..........  1% 2.73M 16m7s\n",
      " 30300K .......... .......... .......... .......... ..........  1% 3.10M 16m7s\n",
      " 30350K .......... .......... .......... .......... ..........  1% 2.28M 16m7s\n",
      " 30400K .......... .......... .......... .......... ..........  1% 3.01M 16m6s\n",
      " 30450K .......... .......... .......... .......... ..........  1% 2.97M 16m6s\n",
      " 30500K .......... .......... .......... .......... ..........  1% 2.86M 16m5s\n",
      " 30550K .......... .......... .......... .......... ..........  1% 2.92M 16m5s\n",
      " 30600K .......... .......... .......... .......... ..........  1%  219K 16m18s\n",
      " 30650K .......... .......... .......... .......... ..........  1%  231K 16m30s\n",
      " 30700K .......... .......... .......... .......... ..........  1% 20.9M 16m29s\n",
      " 30750K .......... .......... .......... .......... ..........  1% 2.15M 16m28s\n",
      " 30800K .......... .......... .......... .......... ..........  1% 19.9M 16m27s\n",
      " 30850K .......... .......... .......... .......... ..........  1% 18.9M 16m26s\n",
      " 30900K .......... .......... .......... .......... ..........  1% 20.4M 16m24s\n",
      " 30950K .......... .......... .......... .......... ..........  1% 15.7M 16m23s\n",
      " 31000K .......... .......... .......... .......... ..........  1% 20.6M 16m21s\n",
      " 31050K .......... .......... .......... .......... ..........  1% 18.5M 16m20s\n",
      " 31100K .......... .......... .......... .......... ..........  1% 18.2M 16m18s\n",
      " 31150K .......... .......... .......... .......... ..........  1% 16.4M 16m17s\n",
      " 31200K .......... .......... .......... .......... ..........  1% 16.9M 16m16s\n",
      " 31250K .......... .......... .......... .......... ..........  1% 19.4M 16m14s\n",
      " 31300K .......... .......... .......... .......... ..........  1% 5.53M 16m13s\n",
      " 31350K .......... .......... .......... .......... ..........  1% 13.5M 16m12s\n",
      " 31400K .......... .......... .......... .......... ..........  1% 16.2M 16m10s\n",
      " 31450K .......... .......... .......... .......... ..........  1% 9.67M 16m9s\n",
      " 31500K .......... .......... .......... .......... ..........  1% 11.7M 16m8s\n",
      " 31550K .......... .......... .......... .......... ..........  1% 6.24M 16m7s\n",
      " 31600K .......... .......... .......... .......... ..........  1% 14.8M 16m5s\n",
      " 31650K .......... .......... .......... .......... ..........  1% 1.56M 16m6s\n",
      " 31700K .......... .......... .......... .......... ..........  1% 2.54M 16m6s\n",
      " 31750K .......... .......... .......... .......... ..........  1% 21.8M 16m4s\n",
      " 31800K .......... .......... .......... .......... ..........  1% 1.81M 16m4s\n",
      " 31850K .......... .......... .......... .......... ..........  1% 28.8M 16m3s\n",
      " 31900K .......... .......... .......... .......... ..........  1% 37.3M 16m1s\n",
      " 31950K .......... .......... .......... .......... ..........  1% 33.4M 16m0s\n",
      " 32000K .......... .......... .......... .......... ..........  1% 30.3M 15m59s\n",
      " 32050K .......... .......... .......... .......... ..........  1% 29.3M 15m57s\n",
      " 32100K .......... .......... .......... .......... ..........  1% 32.5M 15m56s\n",
      " 32150K .......... .......... .......... .......... ..........  1% 24.1M 15m54s\n",
      " 32200K .......... .......... .......... .......... ..........  1% 29.9M 15m53s\n",
      " 32250K .......... .......... .......... .......... ..........  1% 32.2M 15m51s\n",
      " 32300K .......... .......... .......... .......... ..........  1% 36.0M 15m50s\n",
      " 32350K .......... .......... .......... .......... ..........  1% 27.5M 15m49s\n",
      " 32400K .......... .......... .......... .......... ..........  1% 27.3M 15m47s\n",
      " 32450K .......... .......... .......... .......... ..........  1% 33.7M 15m46s\n",
      " 32500K .......... .......... .......... .......... ..........  1% 3.96M 15m45s\n",
      " 32550K .......... .......... .......... .......... ..........  1% 2.97M 15m45s\n",
      " 32600K .......... .......... .......... .......... ..........  1% 3.34M 15m44s\n",
      " 32650K .......... .......... .......... .......... ..........  1% 3.07M 15m44s\n",
      " 32700K .......... .......... .......... .......... ..........  1% 2.98M 15m43s\n",
      " 32750K .......... .......... .......... .......... ..........  1% 2.48M 15m43s\n",
      " 32800K .......... .......... .......... .......... ..........  1% 3.06M 15m42s\n",
      " 32850K .......... .......... .......... .......... ..........  1% 2.94M 15m42s\n",
      " 32900K .......... .......... .......... .......... ..........  1% 3.19M 15m41s\n",
      " 32950K .......... .......... .......... .......... ..........  1% 3.08M 15m41s\n",
      " 33000K .......... .......... .......... .......... ..........  1% 3.05M 15m40s\n",
      " 33050K .......... .......... .......... .......... ..........  1% 3.54M 15m40s\n",
      " 33100K .......... .......... .......... .......... ..........  1% 2.91M 15m39s\n",
      " 33150K .......... .......... .......... .......... ..........  1% 2.35M 15m39s\n",
      " 33200K .......... .......... .......... .......... ..........  1% 3.06M 15m39s\n",
      " 33250K .......... .......... .......... .......... ..........  1% 2.94M 15m38s\n",
      " 33300K .......... .......... .......... .......... ..........  1% 3.15M 15m38s\n",
      " 33350K .......... .......... .......... .......... ..........  1% 2.82M 15m37s\n",
      " 33400K .......... .......... .......... .......... ..........  1% 2.96M 15m37s\n",
      " 33450K .......... .......... .......... .......... ..........  1% 3.18M 15m36s\n",
      " 33500K .......... .......... .......... .......... ..........  1% 3.14M 15m36s\n",
      " 33550K .......... .......... .......... .......... ..........  1% 2.32M 15m36s\n",
      " 33600K .......... .......... .......... .......... ..........  1% 3.08M 15m35s\n",
      " 33650K .......... .......... .......... .......... ..........  1% 2.76M 15m35s\n",
      " 33700K .......... .......... .......... .......... ..........  1% 2.79M 15m34s\n",
      " 33750K .......... .......... .......... .......... ..........  1% 2.73M 15m34s\n",
      " 33800K .......... .......... .......... .......... ..........  1% 3.06M 15m34s\n",
      " 33850K .......... .......... .......... .......... ..........  1% 2.78M 15m33s\n",
      " 33900K .......... .......... .......... .......... ..........  1%  211K 15m46s\n",
      " 33950K .......... .......... .......... .......... ..........  1% 2.46M 15m45s\n",
      " 34000K .......... .......... .......... .......... ..........  1% 4.37M 15m45s\n",
      " 34050K .......... .......... .......... .......... ..........  1% 2.29M 15m45s\n",
      " 34100K .......... .......... .......... .......... ..........  1% 2.29M 15m44s\n",
      " 34150K .......... .......... .......... .......... ..........  1% 3.08M 15m44s\n",
      " 34200K .......... .......... .......... .......... ..........  1%  220K 15m56s\n",
      " 34250K .......... .......... .......... .......... ..........  1% 32.1M 15m54s\n",
      " 34300K .......... .......... .......... .......... ..........  1% 36.0M 15m53s\n",
      " 34350K .......... .......... .......... .......... ..........  1% 1.33M 15m54s\n",
      " 34400K .......... .......... .......... .......... ..........  1% 2.20M 15m54s\n",
      " 34450K .......... .......... .......... .......... ..........  1% 29.6M 15m52s\n",
      " 34500K .......... .......... .......... .......... ..........  1% 1.60M 15m53s\n",
      " 34550K .......... .......... .......... .......... ..........  1% 23.2M 15m51s\n",
      " 34600K .......... .......... .......... .......... ..........  1% 29.6M 15m50s\n",
      " 34650K .......... .......... .......... .......... ..........  1% 1.13M 15m51s\n",
      " 34700K .......... .......... .......... .......... ..........  1% 1.40M 15m52s\n",
      " 34750K .......... .......... .......... .......... ..........  1%  235K 16m2s\n",
      " 34800K .......... .......... .......... .......... ..........  1% 18.4M 16m1s\n",
      " 34850K .......... .......... .......... .......... ..........  1% 21.0M 16m0s\n",
      " 34900K .......... .......... .......... .......... ..........  1% 19.4M 15m59s\n",
      " 34950K .......... .......... .......... .......... ..........  1% 18.9M 15m57s\n",
      " 35000K .......... .......... .......... .......... ..........  1% 19.4M 15m56s\n",
      " 35050K .......... .......... .......... .......... ..........  1% 19.8M 15m55s\n",
      " 35100K .......... .......... .......... .......... ..........  1% 20.6M 15m54s\n",
      " 35150K .......... .......... .......... .......... ..........  1% 18.5M 15m52s\n",
      " 35200K .......... .......... .......... .......... ..........  1% 19.2M 15m51s\n",
      " 35250K .......... .......... .......... .......... ..........  1% 18.9M 15m50s\n",
      " 35300K .......... .......... .......... .......... ..........  1% 22.4M 15m49s\n",
      " 35350K .......... .......... .......... .......... ..........  1% 14.6M 15m47s\n",
      " 35400K .......... .......... .......... .......... ..........  1% 20.2M 15m46s\n",
      " 35450K .......... .......... .......... .......... ..........  1% 21.0M 15m45s\n",
      " 35500K .......... .......... .......... .......... ..........  1% 18.9M 15m44s\n",
      " 35550K .......... .......... .......... .......... ..........  1% 17.4M 15m43s\n",
      " 35600K .......... .......... .......... .......... ..........  1% 16.7M 15m41s\n",
      " 35650K .......... .......... .......... .......... ..........  1% 14.0M 15m40s\n",
      " 35700K .......... .......... .......... .......... ..........  1% 22.9M 15m39s\n",
      " 35750K .......... .......... .......... .......... ..........  1% 13.8M 15m38s\n",
      " 35800K .......... .......... .......... .......... ..........  1% 18.8M 15m37s\n",
      " 35850K .......... .......... .......... .......... ..........  1% 20.5M 15m36s\n",
      " 35900K .......... .......... .......... .......... ..........  1% 15.0M 15m34s\n",
      " 35950K .......... .......... .......... .......... ..........  1% 17.1M 15m33s\n",
      " 36000K .......... .......... .......... .......... ..........  1% 16.4M 15m32s\n",
      " 36050K .......... .......... .......... .......... ..........  1% 23.0M 15m31s\n",
      " 36100K .......... .......... .......... .......... ..........  1% 19.6M 15m30s\n",
      " 36150K .......... .......... .......... .......... ..........  1% 17.8M 15m29s\n",
      " 36200K .......... .......... .......... .......... ..........  1% 18.5M 15m27s\n",
      " 36250K .......... .......... .......... .......... ..........  1% 22.7M 15m26s\n",
      " 36300K .......... .......... .......... .......... ..........  1% 21.3M 15m25s\n",
      " 36350K .......... .......... .......... .......... ..........  1% 17.3M 15m24s\n",
      " 36400K .......... .......... .......... .......... ..........  1% 22.0M 15m23s\n",
      " 36450K .......... .......... .......... .......... ..........  1% 24.8M 15m22s\n",
      " 36500K .......... .......... .......... .......... ..........  1% 19.2M 15m20s\n",
      " 36550K .......... .......... .......... .......... ..........  1% 13.8M 15m19s\n",
      " 36600K .......... .......... .......... .......... ..........  1% 26.0M 15m18s\n",
      " 36650K .......... .......... .......... .......... ..........  1% 22.4M 15m17s\n",
      " 36700K .......... .......... .......... .......... ..........  1% 19.0M 15m16s\n",
      " 36750K .......... .......... .......... .......... ..........  1% 14.4M 15m15s\n",
      " 36800K .......... .......... .......... .......... ..........  1% 18.6M 15m14s\n",
      " 36850K .......... .......... .......... .......... ..........  1% 19.0M 15m12s\n",
      " 36900K .......... .......... .......... .......... ..........  1% 9.14M 15m12s\n",
      " 36950K .......... .......... .......... .......... ..........  1% 2.30M 15m11s\n",
      " 37000K .......... .......... .......... .......... ..........  1% 3.05M 15m11s\n",
      " 37050K .......... .......... .......... .......... ..........  1% 3.08M 15m11s\n",
      " 37100K .......... .......... .......... .......... ..........  1% 2.88M 15m10s\n",
      " 37150K .......... .......... .......... .......... ..........  1% 2.81M 15m10s\n",
      " 37200K .......... .......... .......... .......... ..........  1% 3.23M 15m9s\n",
      " 37250K .......... .......... .......... .......... ..........  1% 3.18M 15m9s\n",
      " 37300K .......... .......... .......... .......... ..........  1% 3.08M 15m9s\n",
      " 37350K .......... .......... .......... .......... ..........  1% 2.43M 15m8s\n",
      " 37400K .......... .......... .......... .......... ..........  1% 3.09M 15m8s\n",
      " 37450K .......... .......... .......... .......... ..........  1% 3.07M 15m8s\n",
      " 37500K .......... .......... .......... .......... ..........  1% 2.91M 15m7s\n",
      " 37550K .......... .......... .......... .......... ..........  1% 2.97M 15m7s\n",
      " 37600K .......... .......... .......... .......... ..........  1% 2.97M 15m7s\n",
      " 37650K .......... .......... .......... .......... ..........  1% 3.30M 15m6s\n",
      " 37700K .......... .......... .......... .......... ..........  1%  213K 15m17s\n",
      " 37750K .......... .......... .......... .......... ..........  1% 3.64M 15m17s\n",
      " 37800K .......... .......... .......... .......... ..........  1% 3.24M 15m16s\n",
      " 37850K .......... .......... .......... .......... ..........  1%  228K 15m26s\n",
      " 37900K .......... .......... .......... .......... ..........  1% 2.19M 15m26s\n",
      " 37950K .......... .......... .......... .......... ..........  1% 23.3M 15m25s\n",
      " 38000K .......... .......... .......... .......... ..........  1% 25.4M 15m24s\n",
      " 38050K .......... .......... .......... .......... ..........  1% 26.9M 15m23s\n",
      " 38100K .......... .......... .......... .......... ..........  1% 30.2M 15m22s\n",
      " 38150K .......... .......... .......... .......... ..........  1% 23.4M 15m21s\n",
      " 38200K .......... .......... .......... .......... ..........  1%  629K 15m24s\n",
      " 38250K .......... .......... .......... .......... ..........  1% 19.6M 15m23s\n",
      " 38300K .......... .......... .......... .......... ..........  1% 17.9M 15m21s\n",
      " 38350K .......... .......... .......... .......... ..........  1% 17.6M 15m20s\n",
      " 38400K .......... .......... .......... .......... ..........  1% 22.9M 15m19s\n",
      " 38450K .......... .......... .......... .......... ..........  1%  731K 15m22s\n",
      " 38500K .......... .......... .......... .......... ..........  1% 3.36M 15m21s\n",
      " 38550K .......... .......... .......... .......... ..........  1% 32.0M 15m20s\n",
      " 38600K .......... .......... .......... .......... ..........  1% 34.5M 15m19s\n",
      " 38650K .......... .......... .......... .......... ..........  1% 32.3M 15m18s\n",
      " 38700K .......... .......... .......... .......... ..........  1% 41.8M 15m16s\n",
      " 38750K .......... .......... .......... .......... ..........  1% 27.9M 15m15s\n",
      " 38800K .......... .......... .......... .......... ..........  1% 39.2M 15m14s\n",
      " 38850K .......... .......... .......... .......... ..........  1% 30.9M 15m13s\n",
      " 38900K .......... .......... .......... .......... ..........  1% 28.1M 15m12s\n",
      " 38950K .......... .......... .......... .......... ..........  1% 33.6M 15m11s\n",
      " 39000K .......... .......... .......... .......... ..........  1% 39.0M 15m10s\n",
      " 39050K .......... .......... .......... .......... ..........  1% 43.9M 15m9s\n",
      " 39100K .......... .......... .......... .......... ..........  1% 40.2M 15m8s\n",
      " 39150K .......... .......... .......... .......... ..........  1% 30.4M 15m6s\n",
      " 39200K .......... .......... .......... .......... ..........  1% 40.9M 15m5s\n",
      " 39250K .......... .......... .......... .......... ..........  1% 41.9M 15m4s\n",
      " 39300K .......... .......... .......... .......... ..........  1% 23.2M 15m3s\n",
      " 39350K .......... .......... .......... .......... ..........  1% 33.9M 15m2s\n",
      " 39400K .......... .......... .......... .......... ..........  1% 36.9M 15m1s\n",
      " 39450K .......... .......... .......... .......... ..........  1% 24.4M 15m0s\n",
      " 39500K .......... .......... .......... .......... ..........  1% 36.7M 14m59s\n",
      " 39550K .......... .......... .......... .......... ..........  1% 34.7M 14m58s\n",
      " 39600K .......... .......... .......... .......... ..........  1% 29.7M 14m57s\n",
      " 39650K .......... .......... .......... .......... ..........  1% 28.2M 14m56s\n",
      " 39700K .......... .......... .......... .......... ..........  1% 33.4M 14m54s\n",
      " 39750K .......... .......... .......... .......... ..........  1% 20.8M 14m53s\n",
      " 39800K .......... .......... .......... .......... ..........  1% 3.04M 14m53s\n",
      " 39850K .......... .......... .......... .......... ..........  1% 3.17M 14m53s\n",
      " 39900K .......... .......... .......... .......... ..........  1% 2.98M 14m52s\n",
      " 39950K .......... .......... .......... .......... ..........  1% 3.13M 14m52s\n",
      " 40000K .......... .......... .......... .......... ..........  1% 2.90M 14m52s\n",
      " 40050K .......... .......... .......... .......... ..........  1% 3.22M 14m51s\n",
      " 40100K .......... .......... .......... .......... ..........  1% 3.19M 14m51s\n",
      " 40150K .......... .......... .......... .......... ..........  1% 2.39M 14m51s\n",
      " 40200K .......... .......... .......... .......... ..........  1% 3.24M 14m50s\n",
      " 40250K .......... .......... .......... .......... ..........  1% 3.01M 14m50s\n",
      " 40300K .......... .......... .......... .......... ..........  2% 3.13M 14m50s\n",
      " 40350K .......... .......... .......... .......... ..........  2% 2.90M 14m49s\n",
      " 40400K .......... .......... .......... .......... ..........  2% 3.22M 14m49s\n",
      " 40450K .......... .......... .......... .......... ..........  2%  230K 14m59s\n",
      " 40500K .......... .......... .......... .......... ..........  2% 3.28M 14m58s\n",
      " 40550K .......... .......... .......... .......... ..........  2% 2.69M 14m58s\n",
      " 40600K .......... .......... .......... .......... ..........  2% 5.59M 14m57s\n",
      " 40650K .......... .......... .......... .......... ..........  2% 10.8M 14m56s\n",
      " 40700K .......... .......... .......... .......... ..........  2% 1.29M 14m57s\n",
      " 40750K .......... .......... .......... .......... ..........  2% 4.23M 14m56s\n",
      " 40800K .......... .......... .......... .......... ..........  2%  222K 15m6s\n",
      " 40850K .......... .......... .......... .......... ..........  2% 17.4M 15m5s\n",
      " 40900K .......... .......... .......... .......... ..........  2% 21.1M 15m4s\n",
      " 40950K .......... .......... .......... .......... ..........  2% 17.1M 15m3s\n",
      " 41000K .......... .......... .......... .......... ..........  2% 20.6M 15m2s\n",
      " 41050K .......... .......... .......... .......... ..........  2% 20.3M 15m1s\n",
      " 41100K .......... .......... .......... .......... ..........  2% 20.1M 15m0s\n",
      " 41150K .......... .......... .......... .......... ..........  2% 19.7M 14m59s\n",
      " 41200K .......... .......... .......... .......... ..........  2% 20.9M 14m58s\n",
      " 41250K .......... .......... .......... .......... ..........  2% 19.7M 14m57s\n",
      " 41300K .......... .......... .......... .......... ..........  2% 23.0M 14m56s\n",
      " 41350K .......... .......... .......... .......... ..........  2% 18.2M 14m55s\n",
      " 41400K .......... .......... .......... .......... ..........  2% 22.4M 14m54s\n",
      " 41450K .......... .......... .......... .......... ..........  2% 19.7M 14m53s\n",
      " 41500K .......... .......... .......... .......... ..........  2% 6.82M 14m52s\n",
      " 41550K .......... .......... .......... .......... ..........  2% 19.0M 14m51s\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41600K .......... .......... .......... .......... ..........  2% 28.3M 14m50s\n",
      " 41650K .......... .......... .......... .......... ..........  2% 23.0M 14m49s\n",
      " 41700K .......... .......... .......... .......... ..........  2% 1.17M 14m50s\n",
      " 41750K .......... .......... .......... .......... ..........  2% 2.25M 14m50s\n",
      " 41800K .......... .......... .......... .......... ..........  2% 3.69M 14m50s\n",
      " 41850K .......... .......... .......... .......... ..........  2% 3.02M 14m50s\n",
      " 41900K .......... .......... .......... .......... ..........  2% 4.94M 14m49s\n",
      " 41950K .......... .......... .......... .......... ..........  2% 3.30M 14m49s\n",
      " 42000K .......... .......... .......... .......... ..........  2% 40.7M 14m48s\n",
      " 42050K .......... .......... .......... .......... ..........  2% 45.6M 14m46s\n",
      " 42100K .......... .......... .......... .......... ..........  2% 40.3M 14m45s\n",
      " 42150K .......... .......... .......... .......... ..........  2% 38.1M 14m44s\n",
      " 42200K .......... .......... .......... .......... ..........  2% 38.5M 14m43s\n",
      " 42250K .......... .......... .......... .......... ..........  2% 40.6M 14m42s\n",
      " 42300K .......... .......... .......... .......... ..........  2% 27.8M 14m41s\n",
      " 42350K .......... .......... .......... .......... ..........  2% 35.8M 14m40s\n",
      " 42400K .......... .......... .......... .......... ..........  2% 45.1M 14m39s\n",
      " 42450K .......... .......... .......... .......... ..........  2% 44.8M 14m38s\n",
      " 42500K .......... .......... .......... .......... ..........  2% 39.5M 14m37s\n",
      " 42550K .......... .......... .......... .......... ..........  2% 31.0M 14m36s\n",
      " 42600K .......... .......... .......... .......... ..........  2% 40.6M 14m35s\n",
      " 42650K .......... .......... .......... .......... ..........  2% 5.15M 14m35s\n",
      " 42700K .......... .......... .......... .......... ..........  2% 3.16M 14m35s\n",
      " 42750K .......... .......... .......... .......... ..........  2% 3.24M 14m34s\n",
      " 42800K .......... .......... .......... .......... ..........  2% 3.18M 14m34s\n",
      " 42850K .......... .......... .......... .......... ..........  2% 3.41M 14m33s\n",
      " 42900K .......... .......... .......... .......... ..........  2% 3.17M 14m33s\n",
      " 42950K .......... .......... .......... .......... ..........  2% 2.49M 14m33s\n",
      " 43000K .......... .......... .......... .......... ..........  2% 3.47M 14m33s\n",
      " 43050K .......... .......... .......... .......... ..........  2% 3.44M 14m32s\n",
      " 43100K .......... .......... .......... .......... ..........  2% 3.21M 14m32s\n",
      " 43150K .......... .......... .......... .......... ..........  2% 3.40M 14m31s\n",
      " 43200K .......... .......... .......... .......... ..........  2% 3.14M 14m31s\n",
      " 43250K .......... .......... .......... .......... ..........  2% 3.20M 14m31s\n",
      " 43300K .......... .......... .......... .......... ..........  2% 3.13M 14m31s\n",
      " 43350K .......... .......... .......... .......... ..........  2% 2.58M 14m30s\n",
      " 43400K .......... .......... .......... .......... ..........  2% 3.48M 14m30s\n",
      " 43450K .......... .......... .......... .......... ..........  2% 3.20M 14m30s\n",
      " 43500K .......... .......... .......... .......... ..........  2% 3.42M 14m29s\n",
      " 43550K .......... .......... .......... .......... ..........  2% 3.00M 14m29s\n",
      " 43600K .......... .......... .......... .......... ..........  2% 3.31M 14m29s\n",
      " 43650K .......... .......... .......... .......... ..........  2% 3.10M 14m28s\n",
      " 43700K .......... .......... .......... .......... ..........  2% 3.11M 14m28s\n",
      " 43750K .......... .......... .......... .......... ..........  2% 2.17M 14m28s\n",
      " 43800K .......... .......... .......... .......... ..........  2% 2.87M 14m28s\n",
      " 43850K .......... .......... .......... .......... ..........  2% 3.12M 14m27s\n",
      " 43900K .......... .......... .......... .......... ..........  2% 2.95M 14m27s\n",
      " 43950K .......... .......... .......... .......... ..........  2% 2.84M 14m27s\n",
      " 44000K .......... .......... .......... .......... ..........  2% 3.05M 14m27s\n",
      " 44050K .......... .......... .......... .......... ..........  2% 3.04M 14m26s\n",
      " 44100K .......... .......... .......... .......... ..........  2% 2.86M 14m26s\n",
      " 44150K .......... .......... .......... .......... ..........  2% 2.18M 14m26s\n",
      " 44200K .......... .......... .......... .......... ..........  2% 2.82M 14m26s\n",
      " 44250K .......... .......... .......... .......... ..........  2% 2.93M 14m26s\n",
      " 44300K .......... .......... .......... .......... ..........  2% 2.78M 14m25s\n",
      " 44350K .......... .......... .......... .......... ..........  2% 2.83M 14m25s\n",
      " 44400K .......... .......... .......... .......... ..........  2% 2.79M 14m25s\n",
      " 44450K .......... .......... .......... .......... ..........  2% 3.05M 14m25s\n",
      " 44500K .......... .......... .......... .......... ..........  2% 3.23M 14m24s\n",
      " 44550K .......... .......... .......... .......... ..........  2%  211K 14m34s\n",
      " 44600K .......... .......... .......... .......... ..........  2% 2.60M 14m34s\n",
      " 44650K .......... .......... .......... .......... ..........  2% 3.61M 14m33s\n",
      " 44700K .......... .......... .......... .......... ..........  2%  231K 14m42s\n",
      " 44750K .......... .......... .......... .......... ..........  2% 19.0M 14m41s\n",
      " 44800K .......... .......... .......... .......... ..........  2% 20.8M 14m40s\n",
      " 44850K .......... .......... .......... .......... ..........  2% 24.6M 14m39s\n",
      " 44900K .......... .......... .......... .......... ..........  2% 19.7M 14m38s\n",
      " 44950K .......... .......... .......... .......... ..........  2% 20.9M 14m37s\n",
      " 45000K .......... .......... .......... .......... ..........  2% 21.9M 14m36s\n",
      " 45050K .......... .......... .......... .......... ..........  2% 20.4M 14m36s\n",
      " 45100K .......... .......... .......... .......... ..........  2% 22.2M 14m35s\n",
      " 45150K .......... .......... .......... .......... ..........  2% 16.5M 14m34s\n",
      " 45200K .......... .......... .......... .......... ..........  2% 21.6M 14m33s\n",
      " 45250K .......... .......... .......... .......... ..........  2% 22.1M 14m32s\n",
      " 45300K .......... .......... .......... .......... ..........  2% 20.8M 14m31s\n",
      " 45350K .......... .......... .......... .......... ..........  2% 16.7M 14m30s\n",
      " 45400K .......... .......... .......... .......... ..........  2% 23.1M 14m29s\n",
      " 45450K .......... .......... .......... .......... ..........  2% 3.64M 14m29s\n",
      " 45500K .......... .......... .......... .......... ..........  2% 21.3M 14m28s\n",
      " 45550K .......... .......... .......... .......... ..........  2%  873K 14m30s\n",
      " 45600K .......... .......... .......... .......... ..........  2% 4.93M 14m29s\n",
      " 45650K .......... .......... .......... .......... ..........  2% 2.69M 14m29s\n",
      " 45700K .......... .......... .......... .......... ..........  2% 17.7M 14m28s\n",
      " 45750K .......... .......... .......... .......... ..........  2% 1.51M 14m28s\n",
      " 45800K .......... .......... .......... .......... ..........  2% 20.9M 14m28s\n",
      " 45850K .......... .......... .......... .......... ..........  2% 18.0M 14m27s\n",
      " 45900K .......... .......... .......... .......... ..........  2% 22.5M 14m26s\n",
      " 45950K .......... .......... .......... .......... ..........  2% 20.5M 14m25s\n",
      " 46000K .......... .......... .......... .......... ..........  2% 24.7M 14m24s\n",
      " 46050K .......... .......... .......... .......... ..........  2% 21.2M 14m23s\n",
      " 46100K .......... .......... .......... .......... ..........  2% 24.4M 14m22s\n",
      " 46150K .......... .......... .......... .......... ..........  2% 20.3M 14m22s\n",
      " 46200K .......... .......... .......... .......... ..........  2% 17.6M 14m21s\n",
      " 46250K .......... .......... .......... .......... ..........  2% 24.7M 14m20s\n",
      " 46300K .......... .......... .......... .......... ..........  2% 20.4M 14m19s\n",
      " 46350K .......... .......... .......... .......... ..........  2% 20.2M 14m18s\n",
      " 46400K .......... .......... .......... .......... ..........  2% 23.9M 14m17s\n",
      " 46450K .......... .......... .......... .......... ..........  2% 21.4M 14m16s\n",
      " 46500K .......... .......... .......... .......... ..........  2% 8.97M 14m16s\n",
      " 46550K .......... .......... .......... .......... ..........  2% 2.37M 14m16s\n",
      " 46600K .......... .......... .......... .......... ..........  2% 3.04M 14m15s\n",
      " 46650K .......... .......... .......... .......... ..........  2% 2.89M 14m15s\n",
      " 46700K .......... .......... .......... .......... ..........  2% 2.96M 14m15s\n",
      " 46750K .......... .......... .......... .......... ..........  2% 2.96M 14m15s\n",
      " 46800K .......... .......... .......... .......... ..........  2% 2.82M 14m14s\n",
      " 46850K .......... .......... .......... .......... ..........  2% 3.02M 14m14s\n",
      " 46900K .......... .......... .......... .......... ..........  2% 3.12M 14m14s\n",
      " 46950K .......... .......... .......... .......... ..........  2% 2.20M 14m14s\n",
      " 47000K .......... .......... .......... .......... ..........  2%  112K 14m32s\n",
      " 47050K .......... .......... .......... .......... ..........  2%  231K 14m40s\n",
      " 47100K .......... .......... .......... .......... ..........  2% 17.0M 14m39s\n",
      " 47150K .......... .......... .......... .......... ..........  2% 18.3M 14m38s\n",
      " 47200K .......... .......... .......... .......... ..........  2% 16.1M 14m37s\n",
      " 47250K .......... .......... .......... .......... ..........  2% 20.7M 14m36s\n",
      " 47300K .......... .......... .......... .......... ..........  2% 21.6M 14m36s\n",
      " 47350K .......... .......... .......... .......... ..........  2% 13.7M 14m35s\n",
      " 47400K .......... .......... .......... .......... ..........  2% 18.7M 14m34s\n",
      " 47450K .......... .......... .......... .......... ..........  2% 24.3M 14m33s\n",
      " 47500K .......... .......... .......... .......... ..........  2% 20.8M 14m32s\n",
      " 47550K .......... .......... .......... .......... ..........  2% 17.8M 14m31s\n",
      " 47600K .......... .......... .......... .......... ..........  2% 21.5M 14m31s\n",
      " 47650K .......... .......... .......... .......... ..........  2% 17.6M 14m30s\n",
      " 47700K .......... .......... .......... .......... ..........  2% 22.5M 14m29s\n",
      " 47750K .......... .......... .......... .......... ..........  2% 17.6M 14m28s\n",
      " 47800K .......... .......... .......... .......... ..........  2% 17.0M 14m27s\n",
      " 47850K .......... .......... .......... .......... ..........  2% 18.5M 14m26s\n",
      " 47900K .......... .......... .......... .......... ..........  2% 14.9M 14m26s\n",
      " 47950K .......... .......... .......... .......... ..........  2% 18.9M 14m25s\n",
      " 48000K .......... .......... .......... .......... ..........  2% 22.1M 14m24s\n",
      " 48050K .......... .......... .......... .......... ..........  2% 21.0M 14m23s\n",
      " 48100K .......... .......... .......... .......... ..........  2% 20.7M 14m22s\n",
      " 48150K .......... .......... .......... .......... ..........  2% 18.4M 14m22s\n",
      " 48200K .......... .......... .......... .......... ..........  2% 21.7M 14m21s\n",
      " 48250K .......... .......... .......... .......... ..........  2% 16.2M 14m20s\n",
      " 48300K .......... .......... .......... .......... ..........  2% 19.9M 14m19s\n",
      " 48350K .......... .......... .......... .......... ..........  2% 18.3M 14m18s\n",
      " 48400K .......... .......... .......... .......... ..........  2% 21.2M 14m17s\n",
      " 48450K .......... .......... .......... .......... ..........  2% 21.6M 14m17s\n",
      " 48500K .......... .......... .......... .......... ..........  2% 20.6M 14m16s\n",
      " 48550K .......... .......... .......... .......... ..........  2% 18.4M 14m15s\n",
      " 48600K .......... .......... .......... .......... ..........  2% 19.9M 14m14s\n",
      " 48650K .......... .......... .......... .......... ..........  2% 19.9M 14m13s\n",
      " 48700K .......... .......... .......... .......... ..........  2% 16.3M 14m13s\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/rpwlnn6j39jjme4/kitti_data.zip?dl=0 -O $savedir/prednet_kitti_data.zip --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f9678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c60591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
